{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a5482ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "14e442e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752130095.609431    8622 gpu_device.cc:2019] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:10:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15174570653335819260\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5833228288\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5525595496043096834\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:10:00.0, compute capability: 8.9\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "display(tf.config.list_physical_devices(\"GPU\"))\n",
    "display(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0c5c4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"../datasets/ionosphere/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "38a0ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plotting\n",
    "# display(plt.style.available)\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "# setup defaults\n",
    "plt.rc(\"figure\", autolayout = True)\n",
    "plt.rc(\"axes\", labelweight = \"bold\", labelsize = \"large\",\n",
    "       titleweight = \"bold\", titlesize = 18, titlepad = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "6c45d540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  V1  V2       V3       V4       V5       V6       V7       V8  \\\n",
       "0           1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708   \n",
       "1           2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597   \n",
       "2           3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062   \n",
       "3           4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000   \n",
       "4           5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255   \n",
       "\n",
       "        V9  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "0  1.00000  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1  1.00000  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.88965  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4  0.77152  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "0 -0.54487  0.18641 -0.45300   good  \n",
       "1 -0.06288 -0.13738 -0.02447    bad  \n",
       "2 -0.24180  0.56045 -0.38238   good  \n",
       "3  1.00000 -0.32382  1.00000    bad  \n",
       "4 -0.59573 -0.04608 -0.65697   good  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ionosphere_data = pd.read_csv(\"../datasets/ionosphere/ion.csv\")\n",
    "display(ionosphere_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "24209eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  V1  V2       V3       V4       V5       V6       V7       V8  \\\n",
       "0           1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708   \n",
       "1           2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597   \n",
       "2           3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062   \n",
       "3           4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000   \n",
       "4           5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255   \n",
       "\n",
       "        V9  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "0  1.00000  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1  1.00000  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.88965  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4  0.77152  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "0 -0.54487  0.18641 -0.45300      1  \n",
       "1 -0.06288 -0.13738 -0.02447      0  \n",
       "2 -0.24180  0.56045 -0.38238      1  \n",
       "3  1.00000 -0.32382  1.00000      0  \n",
       "4 -0.59573 -0.04608 -0.65697      1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = ionosphere_data.copy()\n",
    "\n",
    "# good = 1; bad = 0\n",
    "df[\"Class\"] = df[\"Class\"].map({\"good\" : 1,\n",
    "                               \"bad\" : 0,})\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b89825d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97588</td>\n",
       "      <td>-0.10602</td>\n",
       "      <td>0.94601</td>\n",
       "      <td>-0.20800</td>\n",
       "      <td>0.92806</td>\n",
       "      <td>-0.28350</td>\n",
       "      <td>0.85996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22792</td>\n",
       "      <td>-0.81634</td>\n",
       "      <td>0.13659</td>\n",
       "      <td>-0.82510</td>\n",
       "      <td>0.04606</td>\n",
       "      <td>-0.82395</td>\n",
       "      <td>-0.04262</td>\n",
       "      <td>-0.81318</td>\n",
       "      <td>-0.13832</td>\n",
       "      <td>-0.80975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.91010</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.26970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90014</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.34686</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.34845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91353</td>\n",
       "      <td>0.81586</td>\n",
       "      <td>-0.72973</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.39466</td>\n",
       "      <td>0.55735</td>\n",
       "      <td>0.05405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.10976</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05812</td>\n",
       "      <td>0.94525</td>\n",
       "      <td>0.07418</td>\n",
       "      <td>0.99952</td>\n",
       "      <td>0.13231</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91667</td>\n",
       "      <td>0.22431</td>\n",
       "      <td>0.88423</td>\n",
       "      <td>0.23571</td>\n",
       "      <td>0.88568</td>\n",
       "      <td>0.22511</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.29576</td>\n",
       "      <td>0.83574</td>\n",
       "      <td>0.31166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.07380</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03420</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05563</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.20033</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.36743</td>\n",
       "      <td>0.95603</td>\n",
       "      <td>0.48641</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.32492</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.46712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72414</td>\n",
       "      <td>-0.01084</td>\n",
       "      <td>0.79704</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.79015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72611</td>\n",
       "      <td>-0.01478</td>\n",
       "      <td>0.78041</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.74089</td>\n",
       "      <td>-0.05025</td>\n",
       "      <td>0.82956</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.79015</td>\n",
       "      <td>0.00788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84134</td>\n",
       "      <td>-0.18362</td>\n",
       "      <td>0.43644</td>\n",
       "      <td>0.02919</td>\n",
       "      <td>0.93421</td>\n",
       "      <td>-0.00267</td>\n",
       "      <td>0.87947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90066</td>\n",
       "      <td>-0.02778</td>\n",
       "      <td>0.93358</td>\n",
       "      <td>-0.01158</td>\n",
       "      <td>0.61582</td>\n",
       "      <td>-0.32298</td>\n",
       "      <td>0.84463</td>\n",
       "      <td>-0.25706</td>\n",
       "      <td>0.93323</td>\n",
       "      <td>-0.01425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  V1  V2       V3       V4       V5       V6       V7       V8  \\\n",
       "6             7   1   0  0.97588 -0.10602  0.94601 -0.20800  0.92806 -0.28350   \n",
       "52           53   1   0  1.00000  1.00000  1.00000  1.00000  0.91010  1.00000   \n",
       "114         115   1   0  0.91353  0.81586 -0.72973  1.00000 -0.39466  0.55735   \n",
       "45           46   0   0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "106         107   1   0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "..          ...  ..  ..      ...      ...      ...      ...      ...      ...   \n",
       "58           59   1   0  1.00000  0.05812  0.94525  0.07418  0.99952  0.13231   \n",
       "41           42   1   0 -1.00000 -1.00000  1.00000  1.00000  1.00000 -0.14375   \n",
       "14           15   1   0  1.00000  0.07380  1.00000  0.03420  1.00000 -0.05563   \n",
       "155         156   1   0  0.72414 -0.01084  0.79704  0.01084  0.80000  0.00197   \n",
       "50           51   1   0  0.84134 -0.18362  0.43644  0.02919  0.93421 -0.00267   \n",
       "\n",
       "          V9  ...      V25      V26      V27      V28      V29      V30  \\\n",
       "6    0.85996  ...  0.22792 -0.81634  0.13659 -0.82510  0.04606 -0.82395   \n",
       "52  -0.26970  ...  0.90014 -1.00000  1.00000 -1.00000  1.00000 -1.00000   \n",
       "114  0.05405  ... -0.00003  0.00002 -0.00001  0.00000  0.00000  0.00000   \n",
       "45   1.00000  ... -1.00000 -1.00000 -1.00000 -1.00000 -1.00000  1.00000   \n",
       "106  0.00000  ...  0.00000  0.00000  1.00000  0.10976  0.00000  0.00000   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "58   1.00000  ...  0.91667  0.22431  0.88423  0.23571  0.88568  0.22511   \n",
       "41   0.00000  ... -1.00000 -1.00000  1.00000 -1.00000 -1.00000 -1.00000   \n",
       "14   1.00000  ...  1.00000  0.20033  1.00000  0.36743  0.95603  0.48641   \n",
       "155  0.79015  ...  0.72611 -0.01478  0.78041  0.00612  0.74089 -0.05025   \n",
       "50   0.87947  ...  0.90066 -0.02778  0.93358 -0.01158  0.61582 -0.32298   \n",
       "\n",
       "         V31      V32      V33      V34  \n",
       "6   -0.04262 -0.81318 -0.13832 -0.80975  \n",
       "52   1.00000 -0.34686  1.00000  0.34845  \n",
       "114  0.00000  0.00000  0.00000  0.00000  \n",
       "45   1.00000  0.00000  0.00000  0.00000  \n",
       "106  0.00000  0.00000  0.00000  0.00000  \n",
       "..       ...      ...      ...      ...  \n",
       "58   0.78324  0.29576  0.83574  0.31166  \n",
       "41   1.00000  1.00000  0.00000  0.00000  \n",
       "14   1.00000  0.32492  1.00000  0.46712  \n",
       "155  0.82956  0.02956  0.79015  0.00788  \n",
       "50   0.84463 -0.25706  0.93323 -0.01425  \n",
       "\n",
       "[246 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split data\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "# normalize\n",
    "# max_ = df_train.max(axis=0)\n",
    "# min_ = df_train.min(axis=0)\n",
    "# df_train = (df_train - min_) / (max_ - min_)\n",
    "# df_valid = (df_valid - min_) / (max_ - min_)\n",
    "\n",
    "# drop column V2\n",
    "df_train.dropna(axis=1, inplace=True)\n",
    "df_valid.dropna(axis=1, inplace=True)\n",
    "\n",
    "# create training data\n",
    "X_train = df_train.drop(\"Class\", axis=1)\n",
    "X_valid = df_valid.drop(\"Class\", axis=1)\n",
    "y_train = df_train[\"Class\"]\n",
    "y_valid = df_valid[\"Class\"]\n",
    "\n",
    "display(X_train)\n",
    "display(max(X_train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "890d2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras_sequential = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((X_train.shape[1],)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0),\n",
    "        \n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0),\n",
    "        \n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0),\n",
    "\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "66e2f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras_sequential.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"binary_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "27d174e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - binary_accuracy: 0.6382 - loss: 0.6623 - val_binary_accuracy: 0.2476 - val_loss: 1.0571\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 0.9390 - loss: 0.2014 - val_binary_accuracy: 0.2571 - val_loss: 0.9879\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 0.9675 - loss: 0.1095 - val_binary_accuracy: 0.2667 - val_loss: 0.9529\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 0.9756 - loss: 0.0781 - val_binary_accuracy: 0.2857 - val_loss: 0.9203\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 0.9837 - loss: 0.0626 - val_binary_accuracy: 0.2762 - val_loss: 0.8853\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - binary_accuracy: 0.9837 - loss: 0.0521 - val_binary_accuracy: 0.3143 - val_loss: 0.8483\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - binary_accuracy: 0.9837 - loss: 0.0432 - val_binary_accuracy: 0.3810 - val_loss: 0.8100\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - binary_accuracy: 0.9878 - loss: 0.0353 - val_binary_accuracy: 0.4476 - val_loss: 0.7730\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - binary_accuracy: 0.9919 - loss: 0.0288 - val_binary_accuracy: 0.4667 - val_loss: 0.7398\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - binary_accuracy: 0.9959 - loss: 0.0238 - val_binary_accuracy: 0.5143 - val_loss: 0.7114\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 0.0201 - val_binary_accuracy: 0.5619 - val_loss: 0.6876\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 0.0171 - val_binary_accuracy: 0.5619 - val_loss: 0.6678\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - binary_accuracy: 1.0000 - loss: 0.0147 - val_binary_accuracy: 0.6000 - val_loss: 0.6508\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - binary_accuracy: 1.0000 - loss: 0.0127 - val_binary_accuracy: 0.6000 - val_loss: 0.6362\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 0.0111 - val_binary_accuracy: 0.6000 - val_loss: 0.6232\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - binary_accuracy: 1.0000 - loss: 0.0096 - val_binary_accuracy: 0.6667 - val_loss: 0.6111\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 0.0084 - val_binary_accuracy: 0.7238 - val_loss: 0.5996\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 0.0074 - val_binary_accuracy: 0.7524 - val_loss: 0.5883\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 0.0065 - val_binary_accuracy: 0.8000 - val_loss: 0.5772\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 0.0057 - val_binary_accuracy: 0.8286 - val_loss: 0.5662\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 0.0051 - val_binary_accuracy: 0.8571 - val_loss: 0.5552\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 0.0046 - val_binary_accuracy: 0.8857 - val_loss: 0.5445\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0041 - val_binary_accuracy: 0.8762 - val_loss: 0.5339\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0037 - val_binary_accuracy: 0.8857 - val_loss: 0.5235\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 0.0033 - val_binary_accuracy: 0.8857 - val_loss: 0.5134\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 0.0030 - val_binary_accuracy: 0.8857 - val_loss: 0.5037\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 0.0027 - val_binary_accuracy: 0.8762 - val_loss: 0.4942\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 0.0024 - val_binary_accuracy: 0.8667 - val_loss: 0.4851\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 0.0022 - val_binary_accuracy: 0.8667 - val_loss: 0.4763\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 0.0020 - val_binary_accuracy: 0.8667 - val_loss: 0.4678\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 0.0019 - val_binary_accuracy: 0.8571 - val_loss: 0.4597\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 0.0017 - val_binary_accuracy: 0.8571 - val_loss: 0.4520\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0016 - val_binary_accuracy: 0.8571 - val_loss: 0.4446\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0015 - val_binary_accuracy: 0.8571 - val_loss: 0.4375\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0014 - val_binary_accuracy: 0.8571 - val_loss: 0.4307\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0013 - val_binary_accuracy: 0.8571 - val_loss: 0.4242\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 0.0013 - val_binary_accuracy: 0.8571 - val_loss: 0.4180\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 0.0012 - val_binary_accuracy: 0.8571 - val_loss: 0.4122\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 0.0011 - val_binary_accuracy: 0.8571 - val_loss: 0.4066\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 0.0011 - val_binary_accuracy: 0.8571 - val_loss: 0.4014\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 0.0010 - val_binary_accuracy: 0.8667 - val_loss: 0.3964\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 9.5459e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3916\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 9.0965e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3871\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 8.6895e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3829\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 8.3150e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3789\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 7.9685e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3751\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 7.6574e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3715\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 7.3708e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3680\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 7.1062e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3647\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 6.8611e-04 - val_binary_accuracy: 0.8667 - val_loss: 0.3615\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.6315e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3585\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.4184e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3555\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 6.2197e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3527\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 6.0316e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3500\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 5.8573e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3473\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 5.6935e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3448\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 5.5432e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3424\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.4004e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3401\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 5.2655e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3379\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 5.1379e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3358\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.0180e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3338\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 4.9028e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3318\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 4.7939e-04 - val_binary_accuracy: 0.8762 - val_loss: 0.3299\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.6890e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3282\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 4.5890e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3265\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 4.4953e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3248\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.4052e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3233\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.3184e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3218\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.2363e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3203\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.1572e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3189\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.0820e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3175\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.0096e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3161\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.9398e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3147\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.8721e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3134\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 3.8068e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3122\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.7445e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3109\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.6843e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3097\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.6258e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3085\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.5694e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3074\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 3.5158e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3062\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.4628e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3051\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.4113e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3041\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.3625e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3030\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.3140e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3020\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.2677e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3010\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.2212e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.3001\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 3.1772e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2991\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -519756us/step - binary_accuracy: 1.0000 - loss: 3.1337e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2981\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.0919e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2972\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 3.0511e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2963\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.0124e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2954\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.9732e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2945\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 2.9358e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2937\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.8988e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2928\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.8631e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2920\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.8286e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2912\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.7931e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2904\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.7597e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2897\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 2.7270e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2889\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.6944e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2881\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 2.6629e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2873\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 2.6320e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2865\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - binary_accuracy: 1.0000 - loss: 2.6012e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2858\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 2.5718e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2850\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.5428e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2843\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.5145e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2836\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.4863e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2828\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.4590e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2821\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.4321e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2814\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.4055e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2807\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.3796e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2799\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.3544e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2792\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.3292e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2785\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.3048e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2778\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.2805e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2771\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 2.2564e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2764\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.2333e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2756\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 2.2105e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2750\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.1880e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2743\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.1661e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2736\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.1443e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2729\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 2.1228e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2721\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.1017e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2714\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.0811e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2707\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.0604e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2700\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.0412e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2693\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 2.0210e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2686\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 2.0015e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2679\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.9825e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2672\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.9637e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2665\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.9450e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2658\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.9271e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2651\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.9092e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2645\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.8916e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2638\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - binary_accuracy: 1.0000 - loss: 1.8739e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2631\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 1.8568e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2624\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.8399e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2617\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.8239e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2611\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.8074e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2604\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 1.7913e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2598\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.7750e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2591\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 1.7596e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2584\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.7445e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2577\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.7294e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2571\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.7136e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2564\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.6988e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2557\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.6842e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2550\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 1.6699e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2544\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.6558e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2537\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.6418e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2530\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.6282e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2523\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - binary_accuracy: 1.0000 - loss: 1.6144e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2517\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - binary_accuracy: 1.0000 - loss: 1.6010e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2510\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 1.5876e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2504\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 1.5744e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2496\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 1.5617e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2490\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.5492e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2483\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.5365e-04 - val_binary_accuracy: 0.8857 - val_loss: 0.2477\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 1.5241e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2470\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.5120e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2463\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.5000e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2456\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.4880e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2449\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 1.4762e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2442\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.4642e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2436\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.4529e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2429\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.4415e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2422\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.4303e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2415\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.4192e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2407\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.4082e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2400\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.3974e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2393\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.3869e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2386\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.3764e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2379\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - binary_accuracy: 1.0000 - loss: 1.3661e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2371\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.3559e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2364\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.3457e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2357\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 1.3357e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2350\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 1.3258e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2342\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 1.3162e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2335\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 1.3066e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2328\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.2970e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2321\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.2875e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2313\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 1.2782e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2306\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 1.2691e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2299\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 1.2601e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2291\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.2511e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2284\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 1.2423e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2277\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.2334e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2270\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 1.2246e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2262\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.2160e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2255\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 1.2076e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2248\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.1993e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2240\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.1909e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2233\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.1826e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2225\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.1746e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2218\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.1666e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2210\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 1.1587e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2203\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - binary_accuracy: 1.0000 - loss: 1.1508e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2195\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.1431e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2187\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.1354e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2181\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.1278e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2173\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.1203e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2165\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 1.1129e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2158\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.1056e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2151\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 1.0984e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2143\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 1.0911e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2136\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - binary_accuracy: 1.0000 - loss: 1.0840e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2129\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.0770e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2122\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 1.0700e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2114\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.0631e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2107\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 1.0563e-04 - val_binary_accuracy: 0.8952 - val_loss: 0.2100\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 1.0496e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2092\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 1.0430e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2086\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.0363e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2078\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 1.0299e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2071\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 1.0235e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2064\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.0168e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2056\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 1.0104e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2049\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 1.0041e-04 - val_binary_accuracy: 0.9048 - val_loss: 0.2042\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 9.9781e-05 - val_binary_accuracy: 0.9048 - val_loss: 0.2035\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 9.9164e-05 - val_binary_accuracy: 0.9048 - val_loss: 0.2028\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 9.8566e-05 - val_binary_accuracy: 0.9048 - val_loss: 0.2021\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 9.7955e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.2014\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 9.7362e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.2007\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 9.6771e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.2000\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 9.6188e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.1993\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 9.5615e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.1986\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 9.5040e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.1979\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 9.4459e-05 - val_binary_accuracy: 0.9143 - val_loss: 0.1972\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 9.3896e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1966\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - binary_accuracy: 1.0000 - loss: 9.3327e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1959\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 9.2784e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1952\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 9.2238e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1946\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 9.1698e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1940\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 9.1159e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1933\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 9.0635e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1926\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 9.0100e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1920\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 8.9579e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1913\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 8.9047e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1908\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 8.8542e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1901\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 8.8022e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1895\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 8.7520e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1889\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 8.7017e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1883\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 8.6511e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1877\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 8.6036e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1870\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 8.5539e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1864\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 8.5075e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1859\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 8.4590e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1853\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 8.4109e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1847\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 8.3636e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1841\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 8.3182e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1835\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 8.2726e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1830\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 8.2263e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1824\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 8.1813e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1819\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 8.1351e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1814\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 8.0896e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1808\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 8.0456e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1802\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 8.0015e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1797\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 7.9582e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1792\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 7.9161e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1787\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 7.8750e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1781\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - binary_accuracy: 1.0000 - loss: 7.8315e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1776\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 7.7892e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1771\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 7.7471e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1766\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - binary_accuracy: 1.0000 - loss: 7.7070e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1761\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 7.6649e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1755\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 7.6250e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1750\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 7.5839e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1745\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 7.5428e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1740\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 7.5044e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1735\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 7.4660e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1731\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 7.4259e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1726\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 7.3876e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1721\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 7.3496e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1717\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 7.3113e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1712\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 7.2725e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1708\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 7.2349e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1704\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 7.1994e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1699\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 7.1619e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1695\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 7.1262e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1690\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 7.0910e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1686\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 7.0556e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1682\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 7.0201e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1678\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 6.9854e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1673\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.9510e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1669\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 6.9165e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1665\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - binary_accuracy: 1.0000 - loss: 6.8820e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1661\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 6.8475e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1657\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 6.8140e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1653\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.7811e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1649\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.7474e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1645\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.7150e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1641\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.6825e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1638\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.6504e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1634\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 6.6184e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1630\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 6.5867e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1626\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 6.5548e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1623\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 6.5236e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1619\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 6.4936e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1616\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 6.4620e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1613\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 6.4305e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1609\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 6.4006e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1606\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.3702e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1602\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.3409e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1599\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.3102e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1596\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 6.2808e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1593\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 6.2509e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1589\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 6.2219e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1586\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 6.1928e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1584\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - binary_accuracy: 1.0000 - loss: 6.1644e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1580\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 6.1367e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1578\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 6.1075e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1575\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 6.0795e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1571\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 6.0541e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1568\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 6.0252e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1566\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 5.9976e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1563\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.9694e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1560\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - binary_accuracy: 1.0000 - loss: 5.9434e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1558\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.9162e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1555\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.8898e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1553\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 5.8638e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1550\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.8375e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1547\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.8105e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1545\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 5.7845e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1542\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.7590e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1540\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.7332e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1538\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 5.7076e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1536\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 5.6824e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1533\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.6575e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1531\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 5.6322e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1529\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - binary_accuracy: 1.0000 - loss: 5.6082e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1527\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.5831e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1525\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 5.5587e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1523\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.5348e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1521\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 5.5103e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1519\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 5.4860e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1517\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 5.4624e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1515\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 5.4391e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1513\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.4158e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1512\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.3922e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1510\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 5.3693e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1508\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 5.3468e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1507\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 5.3240e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1505\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 5.3016e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1503\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.2789e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1502\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.2565e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1500\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 5.2352e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1499\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 5.2133e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1497\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 5.1909e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1496\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 5.1692e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1495\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 5.1480e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1494\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - binary_accuracy: 1.0000 - loss: 5.1262e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1492\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 5.1047e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1490\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.0835e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1489\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 5.0619e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1488\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 5.0414e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1487\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 5.0204e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1485\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.9999e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1485\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 4.9796e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1483\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 4.9591e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1482\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 4.9386e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1481\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.9193e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1480\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.8987e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1479\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.8786e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1478\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 4.8586e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1477\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 4.8389e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1477\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 4.8195e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1475\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 4.8002e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1474\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - binary_accuracy: 1.0000 - loss: 4.7807e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1473\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.7612e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1473\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.7416e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1472\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.7230e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1471\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 4.7039e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1469\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 4.6855e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1469\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.6669e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1468\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 4.6482e-05 - val_binary_accuracy: 0.9238 - val_loss: 0.1467\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.6294e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1467\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 4.6114e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1467\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.5926e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1466\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.5754e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1465\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 4.5590e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1464\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.5403e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1464\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 4.5223e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1463\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.5055e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1463\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.4875e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1462\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 4.4699e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1462\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - binary_accuracy: 1.0000 - loss: 4.4535e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 4.4360e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.4188e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1460\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 4.4017e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.3848e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1460\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.3683e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1460\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.3522e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.3362e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 4.3201e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.3038e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 4.2877e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1457\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 4.2712e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 4.2556e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1457\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 4.2404e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1457\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.2248e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 4.2090e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - binary_accuracy: 1.0000 - loss: 4.1932e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 4.1773e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 4.1614e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 4.1462e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 4.1308e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 4.1156e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.1003e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 4.0854e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 4.0704e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 4.0561e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 4.0416e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 4.0271e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 4.0126e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.9976e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.9832e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1452\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 3.9689e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - binary_accuracy: 1.0000 - loss: 3.9548e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.9404e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.9263e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.9128e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.8982e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.8844e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.8712e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.8568e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.8433e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.8297e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.8159e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 3.8024e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1452\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.7891e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.7760e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.7626e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1453\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.7497e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - binary_accuracy: 1.0000 - loss: 3.7366e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.7234e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - binary_accuracy: 1.0000 - loss: 3.7103e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.6978e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - binary_accuracy: 1.0000 - loss: 3.6854e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.6725e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1454\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - binary_accuracy: 1.0000 - loss: 3.6596e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.6467e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - binary_accuracy: 1.0000 - loss: 3.6348e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 3.6217e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.6093e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.5974e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1455\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.5855e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.5731e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.5610e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 3.5490e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.5372e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1456\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.5253e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1457\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.5135e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1457\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 3.5020e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.4902e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 3.4783e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 3.4670e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1458\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.4556e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 3.4438e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.4322e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.4212e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1459\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 3.4099e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1460\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.3986e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - binary_accuracy: 1.0000 - loss: 3.3873e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1460\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.3765e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.3658e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -527920us/step - binary_accuracy: 1.0000 - loss: 3.3546e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1461\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.3439e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1462\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 3.3330e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1462\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 3.3219e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1463\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.3118e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1463\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 3.3009e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1463\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 3.2902e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1464\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.2797e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1464\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.2694e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1464\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.2590e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1465\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.2485e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1465\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - binary_accuracy: 1.0000 - loss: 3.2385e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1465\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.2280e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1466\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.2179e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1466\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 3.2079e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1466\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.1979e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1467\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 3.1873e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1467\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.1778e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1468\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.1681e-05 - val_binary_accuracy: 0.9333 - val_loss: 0.1469\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.1580e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1469\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - binary_accuracy: 1.0000 - loss: 3.1486e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1469\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 3.1383e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1470\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 3.1286e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1471\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - binary_accuracy: 1.0000 - loss: 3.1190e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1471\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - binary_accuracy: 1.0000 - loss: 3.1093e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1471\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 3.0994e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1472\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - binary_accuracy: 1.0000 - loss: 3.0900e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1473\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 3.0804e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1473\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.0710e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1474\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.0617e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1474\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 3.0526e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1474\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 3.0427e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1475\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 3.0333e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1475\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 1.0000 - loss: 3.0243e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1476\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 3.0151e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1476\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 3.0061e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1476\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - binary_accuracy: 1.0000 - loss: 2.9965e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1477\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.9872e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1477\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 2.9784e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1478\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 2.9695e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1478\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - binary_accuracy: 1.0000 - loss: 2.9605e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1478\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.9514e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1480\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 2.9426e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1479\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 1.0000 - loss: 2.9336e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1480\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.9253e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1481\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.9162e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1482\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.9075e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1482\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - binary_accuracy: 1.0000 - loss: 2.8988e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1483\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.8900e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1483\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - binary_accuracy: 1.0000 - loss: 2.8813e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1484\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - binary_accuracy: 1.0000 - loss: 2.8727e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1485\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.8643e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1485\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - binary_accuracy: 1.0000 - loss: 2.8557e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1487\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 1.0000 - loss: 2.8468e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1487\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.8382e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1487\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 2.8299e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1488\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.8218e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1489\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - binary_accuracy: 1.0000 - loss: 2.8138e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1490\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - binary_accuracy: 1.0000 - loss: 2.8057e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1490\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - binary_accuracy: 1.0000 - loss: 2.7977e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1491\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - binary_accuracy: 1.0000 - loss: 2.7893e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1491\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - binary_accuracy: 1.0000 - loss: 2.7811e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1492\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 1.0000 - loss: 2.7729e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1493\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 1.0000 - loss: 2.7648e-05 - val_binary_accuracy: 0.9429 - val_loss: 0.1493\n"
     ]
    }
   ],
   "source": [
    "keras_sequential_early_stopping = EarlyStopping(\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history_keras_sequential = model_keras_sequential.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=1000,\n",
    "    callbacks=[keras_sequential_early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4ada409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_binary_accuracy: 0.9428571462631226'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'val_loss: 0.14523720741271973'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHVCAYAAAB8NLYkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVSdJREFUeJzt3XlcVPX+x/HXzAAioojgkisWKYgguKSpaVlpWd5y61pipd60tMWupdWtm5ZlVt5faWVlama2eDPN3VLTW0lapon7rrkj7oIsM/P748joCCijwBmG9/PxOM3MmbN8Dl/Jt99zzvdYnE6nExEREREp8axmFyAiIiIihUPBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETER/iZXYCIFNyOHTuYO3cuq1atYteuXZw4cYKsrCyCg4OJiIigUaNGtGvXjhtuuAGLxWJ2uVIAGzduZNGiRW7znnjiCZOqEZGSzqJnxYp4v5SUFIYPH86iRYsoyK9shw4dGDNmTDFUJlfr22+/5fnnn3ebt3nzZpOqEZGSTj12Il4uOTmZ/v37k5qaWuB1jh07VoQViYiIt1KwE/Fi+/btyzPUValShV69etGsWTNCQ0M5ffo0W7ZsYdmyZSxevNikakVExGw6FSvixZ588kkWLlzoNq9Zs2aMGzeO8uXL57nOgQMH+P7773nooYdc88aOHct7773n+lyjRg2WLFnC8uXL+eyzz/jzzz85fvw499xzD2+88Ybb9jZs2MB///tfVq1axYEDB0hLSyM4OJjatWvTokULevToQY0aNfKsJTs7m1mzZvH999+zefNmjh49it1up2LFioSGhnL99dcTFxdH8+bNiY6Odlv3xIkTfPnll/z000/s3LmTkydPYrPZqFSpEmFhYURHRxMXF8dNN91EtWrVPPq55sjIyGDWrFksXryYjRs3cuzYMWw2G1WqVKFJkyb06NGDuLi4PNd97rnnmDFjhuvzDTfcwJQpU/jll1+YMmUKa9as4fTp01SrVo3bbruNAQMGUKFCBdfyF7fJpTz++OOu6+569erFypUrXd917tyZ119/nWnTpjFz5ky2bdvGqVOnGDlyJF26dHEt53Q6+fHHH5k7dy5r167lyJEjZGVlUbFiRerVq0ebNm3o1q0bwcHBufa/d+9ebr31Vrd5n332GdHR0YwfP54ffviB/fv3U7ZsWRISEujTpw833HCD2747dOjA7t27XfOeeOIJHn/88Vz7Sk1N5aabbsJut7vmTZgwgdatWxfoZyVS2qnHTsRL7d69O1eoq1ixImPGjMk31AFcc801bqEuPx988AHvvvtuvt9nZGQwYsQIpk2bluu748ePc/z4cdauXcvEiRMZNGgQjzzySK71e/fuzapVq3Ktn5KSQkpKClu2bGHu3Lm0bt2aCRMmuL7fuXMnvXr1IiUlxW29rKws9u/fz/79+0lOTmbatGkMHjyYfv36XfZ4L7ZmzRr++c9/sm/fvlzf7dq1i127djF9+nR69OjBiy++iL+//yW353A4GDFiBFOmTHGb/9dffzFp0iR+/vlnvv76a8qVK+dxrZeSlZXFo48+yrJly/Jd5uDBgwwaNIjVq1fn+i6nLX755Rc+/PBD3nrrLW666abL7nfnzp08++yzHDp0yDUvIyODH3/8kaVLlzJkyBD69OkDgMVioWfPnrz++uuuZadPn86AAQOwWt0HZ1iwYIFbqKtevTotW7a8bD0iYtBwJyJeaunSpbnm3XfffVSqVOmqt33w4MFLhjqn08mzzz6bZ6i7WHZ2Nm+//TYffvih2/ypU6fmGeoKYtSoUblCXWHasGEDvXv3zjPUXeyrr77i5Zdfvuxyq1atyhXqLrR161bGjx/vUZ0FsWDBgkuGuuPHj/PQQw/lGeouduzYMR577DFWrFhx2WVHjBjhFuou5HQ6GTVqFP/73/9c87p27eoWavfv389PP/2Ua90FCxa4fe7cuXOu8Cci+VOPnYiX2rhxY655N954Y6FsO6dH5O677+b+++8nNDSUPXv2cPr0aQAWLlyYq7fw+uuvZ9CgQdSqVYuNGzcyatQojh496vp+7Nix3HnnndSpUwfA7XRhzr4SExOpVKkS6enp7N27l3Xr1rF8+fJcf3FfvO4///lP2rRpQ1BQECdPnmTXrl2sXr06z2BwOU6nk3/961+kpaW55tWtW5eBAwcSFRVFRkYG33//PR9//LHrDuTp06fTqVOnS/78nU4nQUFBPPPMM7Ro0YINGzYwbNgw188UYM6cOQwaNAiAhx56iM6dO7Nw4ULefPNNt21dfJ3khadwL5adnY2/vz/9+/fn1ltvxWazsXHjRmrXrg3AmDFj2LVrl9s6t99+Oz179qRChQosW7aM999/n+zsbMDoAXzppZeYN28efn75/xWRlZXFLbfcwsMPP0xwcDALFy5k/Pjxbndtjxo1ijZt2gAQHBxMly5d3MLvtGnTaNu2revz4cOH+f33312fLRaL2+lkEbk8BTsRL3VhaMpRtWrVQtt+hw4dGD16tOvzdddd53r/5Zdfui0bHBzM1KlTCQkJAaB+/fpERETw97//3bVMdnY206ZN49lnnwVwO50G8OCDD9KoUSPX56ioKG677TYGDRrkFn4uXjc4OJjevXsTEBDgmhcbG0unTp0Acq17OatWrWLDhg2uz/7+/kyePNntZ9uwYUMOHDjArFmzXPO+/PLLywbroUOH0qNHD8D4eR4+fNgttP3111+kpaURFBREhQoVqFChAqGhobm2U7NmTY+O6fnnn6dnz56uz/Xr1wcgMzOTb7/91m3Zpk2bul3bFxMTg5+fn9ufhd27d/PLL7+4ha6LRUdHM27cONd4iQ0bNiQ9Pd0tuG3bto1169bRsGFDABITE/n8889d4W/p0qUcPnyYKlWqAMY/KBwOh2v9G2+80eOfhUhpp/5tkVJqwIABec632+25TqF26NDBFepyxMfHuwJEjgt7W2JiYty+69evH0OGDOGjjz5i4cKFbN++3fUX/MUX7F+47unTp+nUqRPDhg3j008/ZdmyZW6nAPO62P9SfvvtN7fPWVlZtGnThvr167tNF4a6vNa7WFBQUK7epWuvvTbXcidPnvSo3ssJDw+ne/fueX63du1a0tPT3eblteyFAT3HhW2Zl86dO+caBLtbt265lvvzzz9d7yMiItyu38vOznYLnvPmzXNbt2vXrpesQURyU4+diJfK61q6Q4cOufWsXSl/f3/q1auX53fHjx8nKyvLbV7Oab2L1apVy20w3cOHD7veP/jgg8ydO5c9e/a4tvvdd9+5rV+xYkU6duzIgAEDqFy5smv+4MGD6dOnD2fPngXO38xwoYiICLp27crDDz/s1pt3OfldF3Y5x44dIzs7O9/TkzVr1sxVR2BgYK7lck55FpbIyMh8j//C9siRV1uGhIRQoUIFt9CZ17oXyqsnLa95F18r+eCDD7pde/ff//6X/v37c+jQIbfrAENCQrj99tsvWYOI5KYeOxEvdfHwHwBJSUmFsu2wsLAivyC9UqVKzJgxg6eeeoqoqKg8H3F2/PhxvvjiC7p37+4WKpo0acKsWbN44IEH8h1KZdeuXYwePZonn3yyyI7hQk6nk4yMjHy/r1ixYq55xXHRf85pzJKidevWbj2Ze/fuZfny5SxYsMDt+rxOnTpRpkwZM0oUKdHUYyfipW6++Wa34SHA6N3o06dPntdlecJms+X7XcWKFfH393frtcvpdbvYX3/95fb5wl43ME6TDhgwgAEDBnD27Fl27drFnj17WL9+PZ9//rnr+rgDBw4wY8YMt2Fa6tSp47ob9fjx4+zevZtdu3axcuVKpk+f7goBP/74I5s2bSIqKqpAx35xECpfvjwzZswo0LN1g4KCCrSP4nSptswr9O3Zs4fGjRu7zTt+/HiuU8QXt+XF9u7dW6B5F2/HYrGQmJjIK6+84pr39ddf5+pJ1WlYkSujHjsRL1WnTh06dOjgNu/YsWM89dRTl7xh4MCBA0yePPmK92uz2WjSpInbvAULFnDixAm3eWvWrMn1TNOmTZu63qekpLj1wAQGBhIVFUX79u15+umnc12Ptn37dtf7i/+Sr1ixIo0aNeKee+7htddey3Vt34XrXs6FA+cCnDp1ij///JOaNWvmOx05coSTJ08WKPx5Kq/x8XJOQV+tuLi4XKeD8xrCJq95zZo1u+S2v/3221zPLf7mm2/yrOFi9957r9tYjIsXL3a7Fq9BgwY0aNDgkvsXkbypx07Eiw0dOpTff//d7ZFiK1as4K677nI9UqxixYqcOnWKrVu3snTpUhYvXkxCQkKBBinOz/3338+vv/7q+nzmzBl69uzJoEGDqF27Nhs2bGDUqFFu6/j5+bldhD9x4kQWLlzILbfcQnx8PHXq1KFChQpkZWWxfv165s6d67b+hWOc5dzY0aZNG2JiYqhZsyZBQUGcPn2aZcuWsXXrVrd1PelJa9KkCVFRUWzatMk174UXXmD9+vXccsstVKlShbNnz7J3717+/PNPlixZwrZt2xg5cmSRhI28rqUcP348HTt2dJ2KrFat2iWHHslPQEAAXbt2ZerUqa55q1at4vHHHycxMdE13MnFT8CoXbs2rVq1uuS2N23axGOPPUbv3r0pV64cCxcu5PPPP3db5tprryU2NjbXuuXKlaNr1658+umnQO7rDvO6CUNECkbBTsSL1ahRg48++oh+/fq5DX9y8OBB3nrrrSLbb4cOHejQoYPbWHZbt25l4MCB+a7z+OOPu8awy7Fv3z4+//zzXH/h5+XCoTWcTifr169n3bp1l12vXLlyl+1dupDFYuG1116jV69errHsMjIymDhxIhMnTizwdgpLTExMrlPf7733nlvYWrx48RUP+/Hkk0/yyy+/uN188sMPP/DDDz/kuby/vz8jRoy4bJAsW7YsP/74Iz/++GO+ywwdOjTf7xITE/nss8/chjcBKFOmDHffffcl9y0i+dOpWBEvFxsby3fffcdtt91W4FOBV3sNnsVi4a233sp3GI0L+fn5MXjwYB577LEr3l///v1p0aKFx+sFBgby5ptvejzkScOGDZk0aVKBw1JAQEChPPEjLxUrVnSNfVdU2//0009JSEi47LKhoaF88MEHNG/e/LLLDhs2jFq1auX7/TPPPMPNN9+c7/e1atXK8/vbb78919A6IlJw6rETKQGqVKnC+++/z/bt25k7dy6rVq1i586dnDx5kqysLMqXL0+dOnVo1KgR7dq1K9BfzJdTpkwZRowYwf33388333zD77//zoEDB0hPTyc4OJhatWrRokULevTokWdA6tevHwkJCfzxxx8kJyeTkpJCamoq6enplC1blho1ahAfH0/Xrl3dBi4GeOedd/jtt9/4448/2Lx5M6mpqRw9ehS73U5wcDARERE0b96cHj16cM0111zR8cXHxzN//nzmzZvH4sWLWb9+PUePHiUrK4vg4GBq1KhBdHQ0LVq04Oabb77k83mv1gsvvECdOnX47rvv2L59u9tTMQrDNddcwxdffMGSJUuYN28ef/75J6mpqWRnZxMSEkK9evVo27Yt3bp1K3BIvuaaa5g5cybjx49n4cKF7N+/n7Jly9KoUSP69u1boD+DDz74IEuWLHGbp9OwIlfH4rz46lcREZEL7N27l1tvvdVt3meffXbV/4A4cOCAW69djRo1WLx4cZHcpCJSWuhUrIiIFLuzZ8/y9ttvu83r0aOHQp3IVdKpWBERKTa9evVi3759pKamug3rUqlSJR544AETKxPxDQp2IiJSbPbt28e+ffvc5vn5+TFy5EiPb4IRkdwU7EREpNhZLBaqVKlCXFwcjz32GDExMWaXJOITdPOEiIiIiI/QzRMiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hNeNY5ednc2JEycoU6YMVqtyp4iIiJRuDoeDjIwMQkJC8PO7dHTzumB34sQJdu3aZXYZIiIiIl4lIiKCsLCwSy7jdcGuTJkyANSuXZty5cqZXI3kxW63s2XLFurVq4fNZjO7HMmH2sn7qY1KBrWT9/P1NkpPT2fXrl2ujHQpXhfsck6/BgYGEhQUZHI1khe73Q5AUFCQT/4C+Qq1k/dTG5UMaifvV1raqCCXqOkiNhEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETERyjYiYiIiPgIBTsRERERH6FgJyIiIuIjFOxERETEa/Xq1YvXXnvN7DJKDAU7ERERER+hYCciIiLiI0p3sHM4zK5ARERECujEiRMMGTKEZs2a0ahRI/7xj3+wa9cu1/f79u3j0UcfpVmzZsTHx3PXXXexbNky17qDBw+mRYsWxMXF0b59e6ZPn27SkRQdvytZaerUqUyYMIGUlBSioqJ46aWXiIuLy3PZb7/9lueff95tXkBAAMnJyVey68KzcjwsGgYPz4HqCebWIiIiYgKn00l6lr1Y91nW34bFYrmidZ977jl2797NuHHjCA4O5q233qJfv37MmjULgBEjRpCdnc3nn39OUFAQ27ZtIygoCIB3332X7du3M378eEJDQ9mzZw9nz54ttOPyFh4Hu3nz5jFy5EiGDx9Oo0aNmDx5Mn379mXBggWEhYXluU5wcDALFixwfb7SBi1UB5Mh8zRsXqBgJyIipY7T6aTbh0ms2n2sWPfbtE4o/330Ro+zwK5du1iyZAlffvkljRs3BuDtt9/m5ptvZvHixVSrVo0DBw7QoUMH6tevD0CtWrVc6+/fv5/o6GhiY2MBqFmzZiEdkXfx+FTspEmTuO++++jatSuRkZEMHz6cwMDAS3ZnWiwWKleu7JrCw8OvquhCEX698Xpki7l1iIiImMQLulkKbPv27fj5+dGoUSPXvNDQUOrWrcuOHTsASExMZNy4cfTo0YMxY8awadMm17L3338/8+bN45577uHNN9/kjz/+KPZjKA4e9dhlZmayfv16+vfv75pntVpp2bIlq1evzne9tLQ0brnlFhwOBw0aNOCf//wn119//SX35XA4sNuLsHu4UiQ2wJmyGUdR7scH5bRLkbaPXDW1k/dTG5UMvtxOXz1ygymnYh0eXOPudDpxOp2udS5uhwu/69y5M61atWLZsmUsX76cjz76iCFDhpCYmEjr1q1ZtGgR//vf/1i+fDkPP/ww999/P0OGDCm8gysinvzZ8yjYHTt2DLvdnuuUa1hYmCstX6xu3bq8/vrr1K9fn1OnTjFx4kR69OjB3LlzqVatWr772rZtmyeleSzgTDaxgPPIVtasXgUWW5HuzxeZfp2kFIjayfupjUoGtZM5Tp8+TUpKChkZGWRnZzN9+nTq1asHwKlTp9ixYwcdOnQAzrdRVFQUUVFRBAUFMWXKFBo2bOjaXkREBBEREVStWpUvvviC9u3bF/9BFaErunnCEwkJCSQkJLh97tixI1999RWDBg3Kd73IyEiCg4OLrjBHLM5lZbDaM4iPCIPQiKLbl4+x2+0kJycTGxuLzaZA7K3UTt5PbVQyqJ3MFRwcTOXKlbnzzjuZO3cuU6ZMYdiwYZQrV44PPviAatWq8dBDD7Fp0ybmzZtHmzZtiIiI4OTJk+zatYuYmBji4+MZO3YsDRo0IDIykszMTLZv305kZCTx8fFmH+JlpaWlsWVLwS4d8yjYhYaGYrPZSE1NdZufmppa4Ovm/P39iY6OZs+ePZdczmq1Fu0vkM0GYZFweD22o9sh/Lqi25ePstls+p9cCaB28n5qo5JB7WQOi8WCxWLBZrPxxhtv8NprrzFgwACysrJo2rQp48ePJzAwEDAu4xoxYgQHDx4kODiYm266ieeffx6bzUZAQADvvPMO+/btIzAwkCZNmvB///d/JaJNPanRo2AXEBBATEwMSUlJ3HbbbYDxQ0xKSiIxMbFA27Db7WzZsoW2bdt6suuiUbkeHF4PRzZDPd/qihUREfEFU6ZMcb0PCQnhzTffzLVMzjVoL774Yr4haMCAAQwYMKBoivQiHp+K7d27N0OHDqVhw4bExcUxefJk0tPT6dKlCwBDhgyhatWqDB48GID33nuP+Ph46tSpw8mTJ5kwYQL79++ne/fuhXskVyLcOEevO2NFRETEF3gc7Dp27MjRo0cZM2YMKSkpREdH88knn7hOxR44cACr9fwoKidPnuSll14iJSWFkJAQYmJi+Oqrr4iMjCy8o7hSOcEuRcFORERESr4runkiMTEx31OvF3aZArzwwgu88MILV7KboqceOxEREfEhpftZsWGRgAXSj8KZ1MsuLiIiIuLNSnewCwiCiuceN3Jks7m1iIiIiFyl0h3sQKdjRURExGco2IUbDwomRT12IiIiUrIp2FWJMl4PbzS3DhEREZGrpGBXOdp4VbATERGREk7BrvK5U7GnD0L6MXNrERERkULXrl07Pv300wItW79+fRYtWlS0BRUhBbvAChBy7s7Yw5vMrUVERETkKijYAVTOuc5ug7l1iIiIiFwFBTuAKueus0tRj52IiJQiTidknineyen0qMSvv/6a1q1b43A43OY/9thjPP/88+zZs4eBAwfy6KOP0qRJE7p27cry5csL7Ue0efNmHnzwQeLi4mjevDkvvfQSZ86ccX2/YsUKunXrRnx8PE2bNqVHjx7s27cPgE2bNtGrVy8SEhJo3LgxXbp0ITk5udBqy8sVPVLM51TRDRQiIlLKOJ0wsQP8taJ491urBfRZABZLgRa/4447ePXVV1mxYgU33ngjAMePH+enn35i/PjxpKWl0aZNG+644w5iY2OZPXs2jz76KAsWLKB69epXVWpaWhp9+/YlISGBb775htTUVF588UVeffVV3njjDbKzsxk4cCDdu3fnP//5D1lZWaxduxbLuWN75plniI6OZtiwYdhsNjZu3Ii/v/9V1XQ5CnagYCciIqVUwcKVmUJCQmjTpg2zZ892BbuFCxcSGhpK8+bNsVqtXH/99axZs4aIiAgGDRrEokWLWLJkSb7PtS+oOXPmkJmZyahRowgKCgLg3//+N48++ijPPPMMfn5+nDp1iltuuYXatWsDcN1117nW379/P3379nXNi4iIuKp6CkLBDs4NUmyBtCNwOgWCK5tdkYiISNGyWIyes6y04t2vf1CBe+tydOrUiZdeeolhw4YREBDA7Nmzueuuu7BarZw5c4YxY8bw/fffc+rUKex2O2fPnmX//v1XXer27dupX7++K9QBNG7cGIfDwc6dO2nWrBldunShb9++tGrVihtvvJE777yTKlWqANC7d29efPFFvvvuO1q2bMkdd9zhCoBFRdfYgfHM2NA6xvsU9dqJiEgpYbFAQLninTwMdWAMV+J0Olm6dCkHDhzg999/p1OnTgCMGjWKxYsX8/e//50pU6Ywc+ZM6tWrR1ZWVmH/tPI0cuRIvv76axISEpg/fz4dOnRgzZo1ADzxxBPMmTOHm2++mV9//ZWOHTvyww8/FGk9CnY5qjQwXjXkiYiIiFcpU6YM7du3Z/bs2cyZM4e6desSExMDwOrVq7n33ntp1qwZ9erVIzw83HXzwtW67rrr2Lx5M2lp53s1//jjD6xWK3Xr1nXNa9CgAf379+err76iXr16zJkzx/Vd3bp1efjhh5k4cSLt27dn+vTphVJbfhTscriGPFlvbh0iIiKSS6dOnVi6dCnTp0939dYB1KlThx9++IFdu3axadMmBg8enOsO2qvZZ0BAAM899xxbtmzh119/5dVXX+Wee+4hPDycv/76i9GjR7N69Wr27dvHzz//zK5du7j22ms5e/Ysr7zyCitWrGDfvn2sWrWK5ORkt2vwioKusctR1Uj+HFKwExER8TYtWrQgJCSEnTt3ugW75557jhdeeIFhw4ZRqVIl+vXr5zYcydUoW7YsEyZM4LXXXqNbt26ULVuW9u3b89xzz7m+37FjBzNmzOD48eNUqVKFnj170qNHD7Kzszl+/DhDhw7lyJEjhIaG0r59e5588slCqS0/FqfTwwFlilhaWhobN26kXr16lC9fvvh2nLIZ3r8B/MvB83vBqs7M/NjtdtasWUN8fDw2m83sciQfaifvpzYqGdRO3s/X2ygnG0VHR7vdyJEXpZccla4Dv0DIOgPHdppdjYiIiIjHdCo2h83PuIFi/x9wcC2EFe05cBERESles2bN4uWXX87zu+rVqzN37txirqjwKdhdqFrDc8FuHcR0NrsaERERKUTt2rWjUaNGeX7n5+cbkcg3jqKwVIszXg8W7XPcREREpPgFBwcTHBxsdhlFStfYXahqQ+P10Dpz6xARERG5Agp2F8oZ8uTkPkg7am4tIiIiIh5SsLtQYAUIjTDe63SsiIiIlDAKdhfT6VgREREpoRTsLlYt1nhVj52IiIiUMAp2F8u5M/bAWnPrEBEREfGQgt3FqscbrykbITPN1FJEREREPKFgd7Hy10BwVXA6dDpWREREShQFu4tZLFA9wXh/YI2ppYiIiIh4QsEuLznBbv9qc+sQERER8YCCXV4U7ERERKQEUrDLyzXxxmvKZsg4bWopIiIiIgWlYJeX8lWhfHXAqRsoREREpMRQsMuPTseKiIhICaNglx8FOxERESlhFOzy4wp2f5hbh4iIiEgBKdjlp0Zj4zV1G6QdNbcWERERkQJQsMtPUCUIizTe71tlbi0iIiIiBaBgdyk1bzBe/1ppbh0iIiIiBaBgdyk1mxqve38ztw4RERGRAlCwu5SazYzXfavA4TC3FhEREZHLULC7lCoNwL8cZJyEI5vNrkZERETkkhTsLsXmd/7uWF1nJyIiIl5Owe5ydJ2diIiIlBAKdpeTc2esgp2IiIh4OQW7y8m5gSJlkwYqFhEREa+mYHc5wZUhvJ7xfk+SubWIiIiIXIKCXUHUaWW87vrF3DpERERELkHBriBygt1uBTsRERHxXgp2BVGnpfF6cC2cPWFuLSIiIiL5ULAriJAaEBoBTofGsxMRERGvpWBXUHVaG6+7fja3DhEREZF8KNgVVM7p2N3Lza1DREREJB8KdgUVce4Giv1/QMZpc2sRERERyYOCXUFVrAMVa4MjW712IiIi4pUU7ArKYoFrbzHeb19ibi0iIiIieVCw88R17YzXHT+aW4eIiIhIHhTsPFG3DWAxnht7Yp/Z1YiIiIi4UbDzRFAlqNHYeL9jqamliIiIiFzsioLd1KlTadeuHbGxsXTv3p21a9cWaL25c+dSv359BgwYcCW79Q66zk5ERES8lMfBbt68eYwcOZKBAwcyY8YMoqKi6Nu3L6mpqZdcb+/evYwaNYqmTZtecbFewXWd3VJwOEwtRURERORCHge7SZMmcd9999G1a1ciIyMZPnw4gYGBTJ8+Pd917HY7zzzzDE888QS1atW6qoJNV7MZBARD2hE4+KfZ1YiIiIi4+HmycGZmJuvXr6d///6ueVarlZYtW7J69ep813v//fcJCwuje/furFq1qkD7cjgc2O12T8orHhYb1ro3Y9k8B8emeTirxpldUbHLaRevbB9xUTt5P7VRyaB28n6+3kaeHJdHwe7YsWPY7XbCwsLc5oeFhbFjx4481/n999/55ptvmDlzpie7Ytu2bR4tX5zCAqOJYA7pf85gU8gdZpdjmuTkZLNLkAJQO3k/tVHJoHbyfmojD4Odp06fPs2QIUN49dVXqVSpkkfrRkZGEhwcXESVXaXra+D8823KndhK/LVVoEJ1sysqVna7neTkZGJjY7HZbGaXI/lQO3k/tVHJoHbyfr7eRmlpaWzZsqVAy3oU7EJDQ7HZbLlulEhNTSU8PDzX8n/99Rf79u3jsccec81znLvhoEGDBixYsIDatWvnuS+r1eq9jVOhmnGt3d6V2Lb/AE37mF2RKWw2m/e2kbionbyf2qhkUDt5P19tI0+OyaNgFxAQQExMDElJSdx2222AEdSSkpJITEzMtfy1117L7Nmz3ea98847nDlzhn/9619Uq1bNk917l/p3wN6VsHl+qQ12IiIi4l08PhXbu3dvhg4dSsOGDYmLi2Py5Mmkp6fTpUsXAIYMGULVqlUZPHgwZcqUoV69em7rV6hQASDX/BKn3p2w+BXYsQwyz0BAObMrEhERkVLO42DXsWNHjh49ypgxY0hJSSE6OppPPvnEdSr2wIEDWK2l4IEWVaKhYh04vhu2LYYGfzO7IhERESnlrujmicTExDxPvQJMmTLlkuu+8cYbV7JL72OxQHQnSHoPNsxUsBMRERHTlYKutSIUY5x+ZvMCyEwztxYREREp9RTsrkaNxhBSG7LOwLYfzK5GRERESjkFu6thsUDMvcb79TNMLUVEREREwe5q5QS7LQt1OlZERERMpWB3tao3hoq1ISsNtiwwuxoREREpxRTsrpbFArHdjfd/fmluLSIiIlKqKdgVhkYPGK/bFsHJA+bWIiIiIqWWgl1hCI+EWi3A6YC1X5tdjYiIiJRSCnaFJf5cr92aqeB0mluLiIiIlEoKdoUlpjP4lYUjW2Dv72ZXIyIiIqWQgl1hCawADe4x3v/xqamliIiISOmkYFeYmvY2XpOnQ/oxc2sRERGRUkfBrjDVag5VG0J2OqzR0CciIiJSvBTsCpPFAk37GO9/n6CbKERERKRYKdgVtrj7IKA8pG6DncvMrkZERERKEQW7wlamPDTqYbz/dZy5tYiIiEipomBXFJo/CliMZ8ce3mR2NSIiIlJKKNgVhfBIiL7beL98jLm1iIiISKmhYFdUWg0yXtdOgxP7TC1FRERESgcFu6JSsynUaQ2OLFiha+1ERESk6CnYFaVWTxmvv38K6cfNrERERERKAQW7onT97VClAWSeMsa1ExERESlCCnZFyWKBlk8a75Peh4xT5tYjIiIiPk3BrqjFdodK10FaKqz40OxqRERExIcp2BU1mx/c8oLx/pexkH7M3HpERETEZynYFYeYLsa1dhknjFOyIiIiIkVAwa44WK3ne+1+HQdnjphbj4iIiPgkBbviEnU3XNMIMk/Dz/9ndjUiIiLigxTsiovFAu1eMt6vHA/Hdptbj4iIiPgcBbviFHkb1G0D9gxYNMzsakRERMTHKNgVJ4sFOrwOWGD9t7DnV7MrEhERER+iYFfcqsVC4weN9wueA4fd3HpERETEZyjYmaHdixBQHvavhlWTzK5GREREfISCnRmCq8Ct/zbeLxoOpw6aW4+IiIj4BAU7szTrC9UbQ8ZJmD/U7GpERETEByjYmcVqg07vgsUGG2bChllmVyQiIiIlnIKdma6Jg9aDjPezn4JTh0wtR0REREo2BTuztX3OuFM2/SjMegKcTrMrEhERkRJKwc5sfgHQ+WOwBcDWhfDHZLMrEhERkRJKwc4bVG1w/i7ZBS9A6nZz6xEREZESScHOW7QYCBE3QdYZmPYgZKaZXZGIiIiUMAp23sJqhS7joVxlOLQO5j1rdkUiIiJSwijYeZMK10C3iWCxwprPYeV4sysSERGREkTBztvUbXP+erv5Q2DL9+bWIyIiIiWGgp03ajUIEhLB6YBvesOBtWZXJCIiIiWAgp03sljg7negblvIPA1f3Acn9pldlYiIiHg5BTtvZfOH+z6DylFw6gB8do+eTCEiIiKXpGDnzcpWhJ7/hZBakLoVPvsbnE4xuyoRERHxUgp23q5ibXhoFpSvDimbjJ67M6lmVyUiIiJeSMGuJKh0LTw0G4KrweH1MLkTnD5sdlUiIiLiZRTsSorwSKPnLriqEe4m3akbKkRERMSNgl1JUrk+9J4PFWpC6jaYdAcc3Wl2VSIiIuIlFOxKmrDroM984/Ts8T1Gz13KFrOrEhERES+gYFcSVaxt9NzlDIUysQPsTjK7KhERETGZgl1JVb4aPDwPqjeG9KPGUCjJ35hdlYiIiJhIwa4kKxcGD8+FqLvBngnT+8KyN8HpNLsyERERMYGCXUkXEAT3TYGWTxiff3wNZj4GWWfNrUtERESKnYKdL7Baof0IuOs/YLHBn18a190d2212ZSIiIlKMFOx8SbO+kDgdylaCA2vg47awdZHZVYmIiEgxUbDzNdfdAv3/d+6mimMwtRssHQUOh9mViYiISBFTsPNFFWtBnwXQpDfghKWvG3fNHv/L7MpERESkCF1RsJs6dSrt2rUjNjaW7t27s3bt2nyX/f777+nSpQtNmzYlPj6ee+65h5kzZ15pvVJQfmWg0ztw7zjwLwe7foJxrWDtf82uTERERIqIx8Fu3rx5jBw5koEDBzJjxgyioqLo27cvqampeS4fEhLCY489xtdff82sWbPo0qULL7zwAj/99NNVFy8FEP8APPoT1GgKGSfg23/AN32M07QiIiLiU/w8XWHSpEncd999dO3aFYDhw4ezdOlSpk+fTr9+/XIt37x5c7fPDz30EDNnzmTVqlXcdNNN+e7H4XBgt9s9LU/yUjECHp6H5afRWH56G8u66Th3/oTjjjcg+h6wWDzaXE67qH28m9rJ+6mNSga1k/fz9Tby5Lg8CnaZmZmsX7+e/v37u+ZZrVZatmzJ6tWrL7u+0+nk119/ZefOnTzzzDOXXHbbtm2elCYFEdKBcq1qUWfNm5Q9vQfb9D4cr9qSPbFPkVW2ssebS05OLoIipbCpnbyf2qhkUDt5P7WRh8Hu2LFj2O12wsLC3OaHhYWxY8eOfNc7deoUbdq0ITMzE6vVyssvv0yrVq0uua/IyEiCg4M9KU8KJB5u6oLj5/9g+eVdKh5aTsixtThvfRlnk95gufzZebvdTnJyMrGxsdhstqIvWa6I2sn7qY1KBrWT9/P1NkpLS2PLli0FWtbjU7FXoly5csycOZO0tDSSkpJ44403qFWrVq7TtBeyWq0+2ThewVYObn0JGnaFWU9g2fc7lvnPwrrp0OldqBJVsM3YbGqjEkDt5P3URiWD2sn7+WobeXJMHt08ERoais1my3WjRGpqKuHh4fnvxGqlTp06REdH06dPHzp06MDHH3/sya6lKFRtAH2/hzvfNO6c/etXGNcS5g+FtKNmVyciIiIe8ijYBQQEEBMTQ1JSkmuew+EgKSmJhISEAm/H4XCQmZnpya6lqFht0Lw/DFwB9TuC0w4rPoSxjWHleLBnm12hiIiIFJDHw5307t2badOmMWPGDLZv386wYcNIT0+nS5cuAAwZMoTRo0e7lv/oo4/45Zdf+Ouvv9i+fTsTJ05k1qxZ/O1vfyu8o5CrV7EW3P8l9JoBlaON4VDmPQMftobtS8yuTkRERArA42vsOnbsyNGjRxkzZgwpKSlER0fzySefuE7FHjhwAKv1fF5MS0tj+PDhHDx4kMDAQK699lreeustOnbsWHhHIYXnunbw6M+wahL8+DqkbIQpnaFuW7jtZajRxOwKRUREJB9XdPNEYmIiiYmJeX43ZcoUt89PP/00Tz/99JXsRsxi84MbHoHYbrDsTfjtE9i5DMa3g+hO0PYFsysUERGRPOhZsZK/sqFwx0h4/Hdo9IAxFMrG2Vg/akWdNaP07FkREREvo2AnlxdaBzqPg8eSIOpuLE4H4X8txPpBM5j/HJw6ZHaFIiIigoKdeKJKFPSYir3P95wMT8Biz4QV4+DdOCPgnTxgdoUiIiKlmoKdeK5GU7beOBp7z2+hRlPIPnsu4DWCuc/Aib1mVygiIlIqKdjJlbv2ZvjHImOIlNo3gj0DfhsP78bD7EFwbLfJBYqIiJQuCnZydSwWY4iU3vPhodkQcRM4sozhUsY2hu8eh6P5P0dYRERECo+CnRQOiwXqtoGH58DD84zePEc2rJ4CY5vCjMfgyDazqxQREfFpCnZS+CJawYPfQd8fIPJ24zFlf34B7zeD6Y9AymazKxQREfFJCnZSdGrdAInfwCNLoN6d4HRA8jR4vzn892E4tN7sCkVERHyKgp0UvRpN4IGvoN8yiLobcML6GTCuJXydCPtXm12hiIiIT1Cwk+JTPR56TIVHf4EG9wIW2DgbPr4ZPrsHdiwDp9PcGkVEREowBTspftUawn2TYUASxP0dLDbYsRQ++xt8cqsR9hwOs6sUEREpcRTsxDxVoqHLx/DkH9DsEfALhH2rjNOzHzSH1VMhO9PsKkVEREoMBTsxX2gE3PU2DFoHNw2GMiFwZAt8NwDGJMCv4yDzjNlVioiIeD0FO/EewZXh1n/D0+vgtuEQXBVO7oUFz8H/NYSloyDtqNlVioiIeC0FO/E+gRWg9SB4ai3c/X9Gj176UVj6uhHwFv4LTu43u0oRERGvo2An3ss/EJr2gcdXQdcJUDUWss5A0nvwTpzxuDI9zUJERMRFwU68n80PYrvBoz9Bz2+gTivjebSrp8B7TWHagxoLT0REBAU7KUksFrj+dug9D/p8bzzNAids+O7cWHj3ws7/aSw8EREptRTspGSq3dx4msVjyy8YC+9HmNzp3Fh4czQWnoiIlDoKdlKyVY3JZyy8nvBBC42FJyIipYqCnfgG11h4yReMhbfZGAvv3UawfCycPWl2lSIiIkVKwU58S3CVc2PhJZ8bC68anNoP379oDJWyaDicOmR2lSIiIkVCwU58U2CIMRbeoLXwt/cg7HrIOAE//wfeiYXZT0HqdrOrFBERKVQKduLb/MpA414wcCX0+AJq3gD2DFj1KYxtAl/3Mq7JExER8QEKdlI6WK0QdRf0/R56z4frOwBO2DgLxreDT++GbYs0VIqIiJRofmYXIFKsLBao09KYDm2A5WMg+b+w6ydjqhYLrQZBg3uNgZFFRERKEPXYSelVtQF0/hCeXAMtBoB/OTiYDNP7wtgEWPExZKaZXaWIiEiBKdiJVKwFd4yEp9fBLf+CoDA4vgfmPwvvNISloyDtqNlVioiIXJaCnUiOoErQdggMWgcd34aKdSAtFZa+Dv8XA/Ofg+N/mV2liIhIvhTsRC4WEAQ3PAJP/AFdJxjX3WWlwYpxxmDH3/aDQ+vNrlJERCQXBTuR/Nj8ILYb9P8JEr+Fum3AaYe1X8O4ljC1O+z6RXfSioiI11CwE7kciwUib4WHZsMjPxp3zGKBrd/Dpx1hwu2wcQ44HGZXKiIipZyCnYgnajSG+ybDE6ugSW+wlYG9v8HXPeH9G+CPzyA7w+wqRUSklFKwE7kSYddBp3dgUDK0/ieUCYHUrTDrCXg3HlZ8BFlnza5SRERKGQU7katRvirc9rIxVEr7EVD+Gji1H+YPMW60+HUcZKWbXaWIiJQSCnYihSGwArR8Ap76E+4aDRVqwumDsOA5I+Alva/BjkVEpMgp2IkUJr8y0Owf8OQfcPc7EFIbTh+ChS/Au3HwyxjIPGN2lSIi4qMU7ESKgl8ZaNrbuMmi0xioWBvOpMAPL8E7cfDzO5Bx2uwqRUTExyjYiRQlvwBo8pAx2PHf3oPQCEg7AoteNnrwfvoPZJwyu0oREfERCnYixcHmD417weO/wz0fQGhd43Fli4fDO7Hwv7fh7EmzqxQRkRJOwU6kONn8IaGnEfA6fwRhkZB+DJa8agS8ZW/C2RNmVykiIiWUgp2IGWx+0KgHDFwJXcZD2PVw9jj8+JoR8Ja+AenHza5SRERKGAU7ETNZbRB3HwxcAV0nQHh9o8du6UjjJosfXzd69ERERApAwU7EG1htENsNBiRBt4lQORoyTsCyUUbAWzIC0o6aXaWIiHg5BTsRb2K1QcOu8Nhy6D4ZqsRAxkn431vGKdpFw+FMqtlVioiIl1KwE/FGVivE3AuP/gz3TYGqsZB5Gn7+jxHwfngZzhwxu0oREfEyCnYi3sxqhQZ/g/7/g79PhWpxkHUGfnnHOEX7/UtwOsXsKkVExEso2ImUBFYrRN9tBLweX8I18UbAWz7GGOh44b/g9GGzqxQREZMp2ImUJBYLRHWEfkvhgWlQvTFkpUHSe0YP3oIX4NRBs6sUERGTKNiJlEQWC9TrAI8sgZ7fQI2mkJ0Ov74P7zaC+UPh1AGzqxQRkWKmYCdSklkscP3t8I9FkDgdat4A2WdhxYdYxzamVvIYOLnP7CpFRKSYKNiJ+AKLBSJvg77fQ68ZUKsFFnsGVXbNxPpeE5g7GE7sNbtKEREpYgp2Ir7EYoHr2kGfBdgTZ3KqUhwWeyb89gm8Gw9znobje8yuUkREioiCnYgvsligbhu2tHoHe69ZEHETOLLg94kwpjHMehKO7Ta7ShERKWQKdiK+LqI1PDwHHp4HddsYAe+PyTC2MXz3OBzdaXaFIiJSSBTsREqLiFbw0GzovQCuvRkc2bB6CoxtAjMHwtEdZlcoIiJXScFOpLSpcyM8+B30+d64Hs9phzWfw9imMOMxSN1udoUiInKFFOxESqvazY07aPsugsjbjYD35xfwXlP4th8c2Wp2hSIi4iEFO5HSrlYzSPwG/rEEru8ATges/RrevwGm/wNSNptdoYiIFJCCnYgYajaBntPgkR+h3p1GwEv+L7zfHL7pA4c3mV2hiIhcxhUFu6lTp9KuXTtiY2Pp3r07a9euzXfZadOm8cADD9CsWTOaNWvGww8/fMnlRcRkNRrDA19B//9B1N2AE9ZNhw9awLSH4NAGsysUEZF8eBzs5s2bx8iRIxk4cCAzZswgKiqKvn37kpqamufyK1as4K677uKzzz7jq6++4pprrqFPnz4cOnToqosXkSJ0TSPoMRX6/wTRnQAnbJgJ426Er3vBwXVmVygiIhfx83SFSZMmcd9999G1a1cAhg8fztKlS5k+fTr9+vXLtfzo0aPdPo8YMYKFCxeSlJTEvffem+9+HA4Hdrvd0/KkGOS0i9rHuxVaO1WJgW6T4dB6rD+9hWXjLDg3OevfjeOmZ+CauEKouPTR71LJoHbyfr7eRp4cl0fBLjMzk/Xr19O/f3/XPKvVSsuWLVm9enWBtpGenk52djYhISGXXG7btm2elCYmSE5ONrsEKYBCbafIQQRWuYdrtk4hdP8yLJvnYNs8h5PhjTl0bTdOVrkBLLp011P6XSoZ1E7eT23kYbA7duwYdrudsLAwt/lhYWHs2FGwwU3ffvttqlSpQsuWLS+5XGRkJMHBwZ6UJ8XEbreTnJxMbGwsNpvN7HIkH0XXTvHQpjOOlE1YfhqNZcNMKhz5gwpH/sAZXg9n88dwxv0d/AILcZ++Sb9LJYPayfv5ehulpaWxZcuWAi3r8anYq/Hxxx8zb948PvvsM8qUKXPJZa1Wq082ji+x2WxqoxKgyNqpWgx0nwjHh8GKj2DVZCxHtmCZ+zT8+Brc8Ag07QvBlQt/3z5Gv0slg9rJ+/lqG3lyTB6dMwkNDcVms+W6USI1NZXw8PBLrjthwgQ+/vhjJkyYQFRUlCe7FRFvVrE2dHgN/rke2r8GIbUg7QgsHQn/FwOzntRYeCIixcSjYBcQEEBMTAxJSUmueQ6Hg6SkJBISEvJdb/z48XzwwQd88sknxMbGXnm1IuK9AkOg5ePw5BroNhGqNwZ7Bvwx2Rjs+PNusGMpOJ1mVyoi4rM8PhXbu3dvhg4dSsOGDYmLi2Py5Mmkp6fTpUsXAIYMGULVqlUZPHgwYJx+HTNmDKNHj6ZGjRqkpKQAEBQURLly5QrxUETEK9j8oGFXiOkCe36FpPdg01zY9oMxVY2FGwcay/gFmF2tiIhP8TjYdezYkaNHjzJmzBhSUlKIjo7mk08+cZ2KPXDgAFbr+Y7Ar776iqysLJ588km37Tz++OM88cQTV1m+iHgtiwXq3GhMqdthxYew+nM4lAwzH4VFw6B5P2jSG4IqmV2tiIhPuKKbJxITE0lMTMzzuylTprh9XrJkyZXsQkR8Sdh10PEtuPl5WDUJVnwMpw/C4ldg2ZsQ0xma9oGazYxAKCIiV0QDTolI8QmqBDcNhkHJ0PkjqBYL2Wfhzy9hwu0wrhWsHA9nT5hdqYhIiaRgJyLFzy8AGvUwHlfWdxHE9zTGvTu8HuY9A6OjYNYTsL9gA5+LiIhBwU5EzGOxQK1mcO8HMHgT3DEKwutDVhr88Rl8fDN81BZWfQoZp8yuVkTE6ynYiYh3KBsKLR6FgSug93yI7Q62ADiwBmY/BW/Xh5kDYXeShkwREclHsT55QkTksiwWqNPSmO4YBWumGmPhpW6DNZ8bU2hdiPs7xN1n3JghIiKAeuxExJuVC4NWT8Ljv0OfhZCQCP7l4NhOWPYGjG0M4281brg4c8TsakVETKceOxHxfhYL1G5hTHe+CZvmwdqvYfsS2Pe7MS14DiJvM3ry6t8J/mXNrlpEpNgp2IlIyRJQDuK6G9Ppw7BuuhHy9q+GLQuMKaA8NLjHOFUbcRNYdXJCREoHBTsRKbmCq0CLx4wpZYsR8NZOgxN7zl+PV6EGxHYzevKqxphdsYhIkdI/Y0XEN1SuB7e+BE/9adxV2+RhCAyBk/vgl3dhXEsY19p4f2yX2dWKiBQJ9diJiG+xWs/fVXvnm7BlodGTt2Wh8ZzaH5Lhh39D1ViI7gTRd0OVBnqUmYj4BAU7EfFdfmWgwd+MKe0obJgJ676F3cuNkHcoGZa+bgyfEn03RHUynlera/JEpIRSsBOR0iGoEjTtY0xnUmHLfNg4x7iz9thOWD7WmIKrQr07jOnatsbNGiIiJYSCnYiUPuXCjDHxEhIh4zRsWwSb5hina08fMgZE/mMy2MpAROtzQa89hEaYXbmIyCUp2IlI6VYmGGLuNabsTNj1PyPgbVkIx3fD9sXGNP9ZqBwF17eHeh2gVnOw+ZtdvYiIGwU7EZEcfgHGIMeRtxk3XqRshq0LYcv3sCcJUjYZ0/Ixxh2317WDum2NsfLCrtMNGCJiOgU7EZG8WCxQJcqYWj0F6ceNnrst38O2HyAtFdbPMCaA4GrGaduI1gp6ImIaBTsRkYIoWxEadjUmhx32rTJuvNj1M/y1Ek4fhHXfGBMo6ImIKRTsREQ8ZbVBrRuMCSDrrPG82l0/exb0REQKmYKdiMjV8g88H9rgfNDb+ZMR9PbmEfTKX4OlTivCrbWhVnmofL169ETkqinYiYgUtlxBLx32XtCjt3clnDqAdd031AFY+x9j/LzqCVAtDq5pZEwhNRX2RMQjCnYiIkXNvyzUvcmYwBX0HDv/x5n1Cwk+vhHL6UOwZYEx5Shb6VzIywl78cZTMvRkDBHJh4KdiEhxOxf0nLVbsiXkDuJj6mM7vA4OrIUDfxpTykZIPwo7fjSmHAHljaB3Yc9eeD2w6X/nIqJgJyJiPv+yULuFMeXIOguHN8DBC8LewXWQeQp2/2JMOfwCoWrM+aBXLRbCrofACsV/LCJiKgU7ERFv5B8INRobUw57FhzZ4t6zd3AtZJ42hl/Zt8p9G8FVjYAXHglhkcb7sEgIraOnZoj4KAU7EZGSwuZv9MxVjYH4+415Dgcc3QEH/zwf9g6thzMpxnNvTx+C3T+7b8fqZ1yrFxZ5PvSF1jVu1qhQwwiVIlIiKdiJiJRkVqsRzsIjjcGTc6Qfh9TtkLoNUrfCka3nP2enG/NSt8KWPLZZrooR8kJqQEitc+/PTRVqQrnKuoFDxEsp2ImI+KKyFaFmE2O6kMMBp/afC3rbjOnIVji+B07sNULfmcPGtP+PvLdtC4AK1aH8NRBcxQiCwVWN9zmv5atBULjx/F2RksrpBHsmZJ4xpqw049KHzDTjs80PItp41Z9zBTsRkdLEaj3f+3bdLe7fOZ2QfgxO/GWEvLym0weNv+iO7TKmywkoD2VDISjUeC1bCYIq5f2+bKjxOTDEeLqHSF4cdsjOgOyz56eMNIKOb4Y9Z8GRmfv7nM9ZF33OPntBYDtzLrSdC3GZ50Kc037pejq+DTc8UjzHXgAKdiIiYrBYjGAVdG78vLzYs+DUgXMh7/C56dAF07l5Zw6DI9u4izfzFJzY40khRrgLrAABweemcsZUpvy59xfMLxOce55/WeNu4QtfdcPI1XM6jXa1Z4EjC7IzIeuMMTaja17G5cOU2+cMY3239S7+fMF2HFm5yrIB0QA/FeGx2wLO/dk692cxIMjora7btgh36jkFOxERKTibP1SsbUyX4nDA2eNGD2D6MUg7eu79Uff3ru+OGtcFZpwEnMa6Z48Xbu0WG/iVAau/0SNoCzCOx+ZvzLvwsy3AuMnEFoDV6k/dU6ex7KpywTIXrWv1M3pDLRdPNuPVajOCs9Np1OJ0nHvvvOD1onlOx0Xfk8c8x/mwlTPlBCz7BfOcdqOny+m84L3dWDY7w+iFdU1ZeWwn6/y2vInVD/wCcfqVIcthwz+oPBa/QKOd/csarzmf/QIvmC6Yn/OPhpx/HPgHuc/L+VxC/mGgYCciIoXPaj3f++cJe9b5sJd52pgyck6PnTp/mizj9AWnzc69Zpw6/zkr/XzPUA6n3Tjl5iELUAlgv8erlg7+QUZIygnD/oH5h6iChC3/PNbzK+u+vH8g2Mq4BuZ22O0kr1lDfHw8NlvpPo2vYCciIt7D5n/uJowqhbM9p/PcabxzQc+eeb4ny555rkcqZ8q8oJfq3HL2TBzZGezds5Oa1apgdWa75hvrZ59/dTrO96DlvHfYL5hvByznevIs595b8p5nsZ57Tx7z8ljO6meEHKvfud7HC95bbUbPofVcD6Lrc06vZYARmlw9lTnr5/RIntuWq2fzwu/8dYe0l1GwExER32WxGL1E/mWveBNOu50U2xpqxMdDKe8NEu+nmC0iIiLiIxTsRERERHyEgp2IiIiIj1CwExEREfERCnYiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETERyjYiYiIiPgIBTsRERERH6FgJyIiIuIjFOxEREREfISCnYiIiIiPULATERER8REKdiIiIiI+QsFORERExEco2ImIiIj4CAU7ERERER+hYCciIiLiIxTsRERERHyEgp2IiIiIj7iiYDd16lTatWtHbGws3bt3Z+3atfkuu3XrVp544gnatWtH/fr1+fTTT6+0VhERERG5BI+D3bx58xg5ciQDBw5kxowZREVF0bdvX1JTU/NcPj09nZo1azJ48GAqV6581QWLiIiISN78PF1h0qRJ3HfffXTt2hWA4cOHs3TpUqZPn06/fv1yLR8XF0dcXBwAo0ePLvB+HA4Hdrvd0/KkGOS0i9rHu6mdvJ/aqGRQO3k/X28jT47Lo2CXmZnJ+vXr6d+/v2ue1WqlZcuWrF692pNNXda2bdsKdXtS+JKTk80uQQpA7eT91EYlg9rJ+6mNPAx2x44dw263ExYW5jY/LCyMHTt2FGphkZGRBAcHF+o2pXDY7XaSk5OJjY3FZrOZXY7kQ+3k/dRGJYPayfv5ehulpaWxZcuWAi3r8anY4mK1Wn2ycXyJzWZTG5UAaifvpzYqGdRO3s9X28iTY/Lo5onQ0FBsNluuGyVSU1MJDw/3ZFMiIiIiUsg8CnYBAQHExMSQlJTkmudwOEhKSiIhIaHQixMRERGRgvP4VGzv3r0ZOnQoDRs2JC4ujsmTJ5Oenk6XLl0AGDJkCFWrVmXw4MGAccPF9u3bXe8PHTrExo0bCQoKok6dOoV4KCIiIiKlm8fBrmPHjhw9epQxY8aQkpJCdHQ0n3zyietU7IEDB7Baz3cEHj58mHvvvdf1eeLEiUycOJEbbriBKVOmXP0RiIiIiAhwhTdPJCYmkpiYmOd3F4e1mjVrsnnz5ivZjYiIiIh4QM+KFREREfERCnYiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETERyjYiYiIiPgIBTsRERERH6FgJyIiIuIjFOxEREREfISCnYiIiIiPULATERER8REKdiIiIiI+QsFORERExEco2ImIiIj4CAU7ERERER+hYCciIiLiIxTsRERERHyEgp2IiIiIj1CwExEREfERCnYiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETERyjYiYiIiPgIBTsRERERH6FgJyIiIuIjFOxEREREfISCnYiIiIiPULATERER8REKdiIiIiI+QsFORERExEco2ImIiIj4CAU7ERERER+hYCciIiLiIxTsRERERHyEgp2IiIiIj1CwExEREfERCnYiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETERyjYiYiIiPiIUh3sTp7Nwul0ml2GiIiISKHwu5KVpk6dyoQJE0hJSSEqKoqXXnqJuLi4fJefP38+7777Lvv27SMiIoJnnnmGtm3bXnHRheH9H7fx1sLNlC/jR71q5alXtTw1KgZSpUIgVSsEUrVCGSqWDSA40I9yATYsFoup9YqIiIhcjsfBbt68eYwcOZLhw4fTqFEjJk+eTN++fVmwYAFhYWG5lv/jjz8YPHgw//znP7nllluYPXs2AwcO5Ntvv6VevXqFchBXonrFQAJsVk5lZLNq9zFW7T6W77JWC5Qr40eFQH+Cy/gRVMZGgM1KGf9zr35WAvzOvwbYjFc/qwWr1YLNcu71wvcWsF38vcXiNs9iAQtgZMoLP1tc863nZl4833LB8lz02VLAbeesg2s5g9PhYNfxLMocOInNZnPNvzj7GlvK/d3FEdl9vYKuY8nzO/d13NfKL5vnqvsqt53P4eRaL791CuMfERbA7rBzKsPBsbRMbFbbZdfJtY1C+LfMxT+nK9zI1W/CO8rI1bZ2u530LAenM7Kx2Qp29qBw6iiEbRRCJd7w7+WC1GC3O8iyO8nIdpBXM3nLz6Io/ox6k0tV5nA4cTidOBxOLJbiOxNnsXjfz8zi9PBcZPfu3YmNjeXf//43AA6Hg7Zt29KrVy/69euXa/lBgwaRnp7ORx995Jp33333ERUVxSuvvJJr+bS0NDZu3EhkZCTBwcGeHo9HMrMd7Ew9w5ZDp9l2+DSHTp7l0MkMDp/K4PDJs5w4m43doVO1IiIiklu5ABvvPRBPm+srF+l+0tLS2LJlC9HR0QQFBV1yWY967DIzM1m/fj39+/d3zbNarbRs2ZLVq1fnuc6aNWt4+OGH3ea1bt2aRYsWXXJf27Zt86S0q1ILqBUOhIPxI/EDyuF0Osm0Q1q2g7QsJ+lZTtKyHJzNdpLlcJLlgGy7k0yHk2w7ZDqcZNmdZDsg0+7E4cT4F4STPN5f7rOTnEjpdHKJ9848v3di/Of8e2c+8y9+78xzfo4LY65b5C3IMjkFFtq2rqaui7ZWqMdYwOVERKREO5tlZ+OW7VQ4s8/sUlw8CnbHjh3DbrfnOuUaFhbGjh078lznyJEjhIeH51r+yJEjl9xXcfTYyZWx2+0kJycTGxvrdipWrsyFneaFcS9PzibsdjvJ65KJbeh5OxXGTUWFEWQL8+dxdRspmp+H3W5n3fr1NIyJKVAbFc7PoxCOxQvapXDueyvYRux2O+s3bCCmQYNc7eQNPwvwnt9Zs9jtdjZu2Eh0g+hi/XspwGalXJkrul3BIzk9dgVR9NVcIavVqtDg5Ww2m9rIi9nPXasZ4O+ndvJSdrudMjYL5QID1EZezG63U87fSsVygWonL2W32ylfxkp4+bI+2UaeHJNHw52EhoZis9lITU11m5+ampqrVy5HeHh4rt65Sy0vIiIiIlfGo2AXEBBATEwMSUlJrnkOh4OkpCQSEhLyXCc+Pp5ff/3Vbd7y5cuJj4/3vFoRERERyZfHAxT37t2badOmMWPGDLZv386wYcNIT0+nS5cuAAwZMoTRo0e7ln/wwQf56aefmDhxItu3b2fs2LGsW7eOxMTEwjsKEREREfH8GruOHTty9OhRxowZQ0pKCtHR0XzyySeuU6sHDhzAaj2fFxs3bszbb7/NO++8w3/+8x8iIiJ4//33TR3DTkRERMQXXdHNE4mJifn2uE2ZMiXXvDvvvJM777zzSnYlIiIiIgVUqp8VKyIiIuJLFOxEREREfISCnYiIiIiPULATERER8REKdiIiIiI+QsFORERExEco2ImIiIj4CAU7ERERER+hYCciIiLiI67oyRNFyeFwAHD27FlsNpvJ1Uhe7HY7AGlpaWojL6Z28n5qo5JB7eT9fL2N0tPTgfMZ6VIsTqfTWdQFeSI1NZVdu3aZXYaIiIiIV4mIiCAsLOySy3hdsMvOzubEiROUKVMGq1VnikVERKR0czgcZGRkEBISgp/fpU+2el2wExEREZEroy4xERERER+hYCciIiLiIxTsRERERHyEgp2IiIiIj/C6YDd16lTatWtHbGws3bt3Z+3atWaXVGr89ttvPProo7Ru3Zr69euzaNEit++dTifvvvsurVu3Ji4ujocffjjX0DTHjx9n8ODBNG7cmKZNm/LCCy9w5syZYjwK3/bRRx/RtWtXEhISuPHGGxkwYAA7duxwWyYjI4Phw4fTvHlzEhISeOKJJzhy5IjbMvv376dfv340atSIG2+8kVGjRpGdnV2ch+KzvvjiCzp16kTjxo1p3Lgxf//731m2bJnre7WP9/n444+pX78+r732mmue2sl8Y8eOpX79+m7THXfc4fpebZQ3rwp28+bNY+TIkQwcOJAZM2YQFRVF3759SU1NNbu0UiEtLY369evz8ssv5/n9+PHjmTJlCsOGDWPatGmULVuWvn37kpGR4VrmmWeeYdu2bUyaNIkPP/yQ33//nX//+9/FdQg+b+XKlfTs2ZNp06YxadIksrOz6du3L2lpaa5lXn/9dX788UfeeecdpkyZwuHDh3n88cdd39vtdvr3709WVhZfffUVb7zxBjNmzGDMmDFmHJLPqVatGs888wzffvst06dPp0WLFgwcOJCtW7cCah9vs3btWr766ivq16/vNl/t5B2uv/56fv75Z9f0xRdfuL5TG+XD6UW6devmHD58uOuz3W53tm7d2vnRRx+ZWFXpVK9ePecPP/zg+uxwOJytWrVyfvLJJ655J0+edDZs2NA5Z84cp9PpdG7bts1Zr14959q1a13LLFu2zFm/fn3nwYMHi6/4UiQ1NdVZr14958qVK51Op9EmMTExzvnz57uWyWmX1atXO51Op3Pp0qXOqKgoZ0pKimuZL774wtm4cWNnRkZGsdZfWjRr1sw5bdo0tY+XOX36tLN9+/bOX375xZmYmOgcMWKE0+nU75G3GDNmjPNvf/tbnt+pjfLnNT12mZmZrF+/npYtW7rmWa1WWrZsyerVq02sTAD27t1LSkqKW/uUL1+eRo0audpn9erVVKhQgdjYWNcyLVu2xGq16pR6ETl16hQAISEhAKxbt46srCy3drruuuuoXr06a9asAWDNmjXUq1eP8PBw1zKtW7fm9OnTbNu2rfiKLwXsdjtz584lLS2NhIQEtY+XeeWVV2jbtq1be4B+j7zJ7t27ad26NbfeeiuDBw9m//79gNroUrzmWbHHjh3DbrfnelRGWFhYrmuIpPilpKQA5Nk+Odc0HDlyhEqVKrl97+fnR0hIiGt9KTwOh4PXX3+dxo0bU69ePcBoA39/fypUqOC2bFhYmKsNjhw54vY/OsD1We1UODZv3kyPHj3IyMggKCiI999/n8jISDZu3Kj28RJz585lw4YNfPPNN7m+0++Rd4iLi2PkyJHUrVuXlJQU3n//fXr27Mns2bPVRpfgNcFORDwzfPhwtm7d6nbNiXiHunXrMnPmTE6dOsXChQsZOnQon3/+udllyTkHDhzgtddeY+LEiZQpU8bsciQfbdu2db2PioqiUaNG3HLLLcyfP5/AwEATK/NuXnMqNjQ0FJvNlutGidTU1FyJW4pf5cqVAS7ZPuHh4Rw9etTt+5xn/+asL4XjlVdeYenSpUyePJlq1aq55oeHh5OVlcXJkyfdlk9NTXW1QXh4eK47x3I+q50KR0BAAHXq1KFhw4YMHjyYqKgoPvvsM7WPl1i/fj2pqal06dKFBg0a0KBBA1auXMmUKVNo0KCB2slLVahQgYiICPbs2aM2ugSvCXYBAQHExMSQlJTkmudwOEhKSiIhIcHEygSgZs2aVK5c2a19Tp8+zZ9//ulqn4SEBE6ePMm6detcy/z66684HA7i4uKKvWZf5HQ6eeWVV/jhhx+YPHkytWrVcvu+YcOG+Pv7u7XTjh072L9/P/Hx8QDEx8ezZcsWt5C+fPlygoODiYyMLJbjKG0cDgeZmZlqHy/RokULZs+ezcyZM11Tw4YN6dSpk+u92sn7nDlzhr/++ovKlSurjS7Bq07F9u7dm6FDh9KwYUPi4uKYPHky6enpdOnSxezSSoUzZ86wZ88e1+e9e/eyceNGQkJCqF69Og8++CDjxo2jTp061KxZk3fffZcqVapw2223AcaFqzfddBMvvfQSw4cPJysri1dffZW77rqLqlWrmnVYPmX48OHMmTOHDz74gHLlyrmuEylfvjyBgYGUL1+erl278sYbbxASEkJwcDAjRowgISHB9T+71q1bExkZyZAhQ3j22WdJSUnhnXfeoWfPngQEBJh4dL5h9OjRtGnThmuuuYYzZ84wZ84cVq5cyYQJE9Q+XiI4ONh1XWqOoKAgKlas6JqvdjLfqFGjuOWWW6hevTqHDx9m7NixWK1W7r77bv0uXYLF6XQ6zS7iQp9//jkTJkwgJSWF6OhoXnzxRRo1amR2WaXCihUrePDBB3PN79y5M2+88QZOp5MxY8Ywbdo0Tp48SZMmTXj55ZepW7eua9njx4/z6quvsmTJEqxWK+3bt+fFF1+kXLlyxXkoPuvisbZyjBw50vUPoIyMDN544w3mzp1LZmYmrVu35uWXX3Y79bBv3z6GDRvGypUrKVu2LJ07d2bw4MH4+XnVv/VKpBdeeIFff/2Vw4cPU758eerXr88jjzxCq1atALWPt+rVqxdRUVH861//AtRO3uDpp5/mt99+4/jx41SqVIkmTZrw9NNPU7t2bUBtlB+vC3YiIiIicmW85ho7EREREbk6CnYiIiIiPkLBTkRERMRHKNiJiIiI+AgFOxEREREfoWAnIiIi4iMU7ERERER8hIKdiIiIiI9QsBMRERHxEQp2IiIiIj5CwU5ERETER/w/VY/aWerEz4kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHVCAYAAAB8NLYkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVXtJREFUeJzt3Xd8VFXi/vFnZiChhBogiAREIwmQhISVunGzFAsgKEGQxVj4ooALuouwoIAKqAQVdkOzgQRELEhRgYjiKupPYyWQUARpiksLoSikz8zvj5iRIXVSZiY3n/frhcncOffOufck8nDOPeea7Ha7XQAAAKj2zJ6uAAAAACoHwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAganm6AgCM4aOPPtL48eMLbb/pppu0cOFCD9QIAGoeeuwAVIr169cXuf3jjz/WuXPn3FsZAKihCHYAKuzMmTP67LPPinwvNzdXmzZtcnONAKBmItgBqLD33ntPubm5xb5fXG8eAKBycY8dgArbsGGD0+s+ffro448/drzevXu39u/fr/bt2xd7DLvdrs8++0yJiYlKSUlRWlqasrKy1LhxY11xxRXq1q2bBg0apJCQkEL75uXl6cMPP9TWrVu1a9cupaenKzc3V02bNtWVV16pnj176rbbblNgYKBTHf/3v/85Xk+YMEEPPvig03EXLVqkxYsXO15feeWVTudV3HHGjh2rFStWKDExUT/99JMyMjL06quvqnv37kpPT9fWrVu1Z88e7du3T+np6Tp37pwyMzNVt25dXXHFFQoNDdXgwYPVs2fPYq+Xq9fsu+++05133unY12Qy6aOPPlLr1q0LHXf58uV65plnHK9btmypTz75RGYzfQGAtyPYAaiQvXv36ocffnDa9vDDD+vEiRPas2ePY9uGDRs0derUIo9x9OhRTZ48WTt27Cj0XlpamtLS0pSSkqKcnBxNnz7d6f09e/Zo0qRJOnToUKF9T5w4oRMnTuj7779XgwYNdO+997p+gi66cOGCRowYod27dxf5fnJysp544oki3/vtt9/022+/af/+/Vq/fr0GDBig5557TrVqFf5ftavX7LrrrlPHjh0dbWK32/X2229r4sSJhfZPTEx0ej1kyBBCHVBN8JsKoEIuH2bt2LGjrr32Wg0ePNhp+8aNG5WXl1do/5MnTyo2NrbIgFKaffv26e677y4y1HnKa6+9Vmyoc1ViYqJTj2GB8l6z2NhYp9fr16+X1Wp12nb06FGlpqY6XptMJg0dOtSlzwHgOfTYASi3oiZG3HrrrZKkgQMH6rnnnnMEh7S0NH3++efq3bu3U/mnn35aJ06ccNrWqVMn3XfffQoODpbNZtO+ffu0ceNGmUwmRxm73a5p06bpt99+c9q3R48euueee9SuXTtlZ2dr165dbr3HLy8vT35+fnrwwQfVq1cv5eXlaefOnWrWrJkkyWw2KyIiQr1791b79u3l7++vRo0aKSsrS0eOHNHKlSu1fft2x/FeffVV/f3vf5ePj49jW3mv2aBBgzRv3jydOXNGknTq1Cl98skn6tevn6PM+++/73Tcbt26OQ1hA/BuBDsA5fbpp586QoIkWSwWDRw4UJLUokUL9ejRQ1988YXj/Q0bNjgFu5MnT+qDDz5wOmZERIRWrVrlFGSuvfZa3XLLLfr1118d25KTk7Vr1y6nfW+66SYtWLDAKcyEhITo9ttvd9q3qs2fP19//etfHa87duzo+L5Pnz7q06dPkfuFhISoe/fu6tGjh2PbxYsXtXfvXnXu3FlSxa6Zj4+Phg8frhdffNGxbc2aNU7BbsuWLU7Hvv3228tyygC8BMEOQLld3hPWq1cvNW/e3PF68ODBTsGuYE27xo0bS5K+/vrrQsccP368U0C5VMOGDR3fF7XvP/7xD6dQV9y+Valjx45Ooa4oaWlpWrt2rb766isdOXJE58+fV1ZWlux2e5HlT5w44Qh2FblmkjRy5EgtW7bMMSz++eef6/jx47riiiv0008/OQ0jN2jQQDfeeGOJ5wLAu3CPHYByKWrtuoJh2AI33HCD6tat63h9+dDtqVOnCh03NDS0TJ9/+b5169bVNddcU6Z9q1KHDh1KfP/jjz/WjTfeqPj4eH311Vc6ceKEMjMziw11kpSRkeH4viLXTJICAgJ00003OV7bbDatXbtWUuFh2FtuuUV16tQp87EBeB7BDkC5FLV23eTJkxUcHOz406VLF2VmZjqV8dY17S6fRCBJZ8+edfk4LVq0KPa9M2fOaPLkyU5BrSxKCn3lcddddzm9XrdunWw2W6HZsAzDAtUPwQ5AuVy+dl1ZFaxpJxUdgi6/b644l++bmZmpgwcPlrkeFovF6XVWVlahMkeOHCnz8Yo77qU+/fRTXbx40WnbHXfcodWrV+vDDz/Uf//730K9ZperyDUrEBkZ6dTLd/z4ca1cuVL79u1zbAsODnapJxCAdyDYAXBZUWvXuaIgFHbv3r3Qe88//7xycnKK3O/SiQBF7btw4cJie7cunzzRoEEDp9eXh8JDhw4pKSmpyGOV18mTJ51e+/n5afbs2bruuuvUtm1btW7d2hF6i1ORa3apu+++2+n1/PnznV7TWwdUTwQ7AC67fDj1iiuu0H//+99i/1y+flrBmnYBAQGFbs5PTk7W3/72N73//vs6dOiQDhw4oA8++EAPPvig05pukZGR6tSpk9O+W7Zs0ejRo/XJJ5/oyJEj2rdvn959913de++9heocHBzs9Przzz/X4sWLtX//fn388ccaN26cbDZbua9RUZo2ber0+sKFC/rPf/6jffv2ac+ePXr55Zc1bdq0Eo9RkWt2qf79+ztNdLl0WN3Hx6fQOoQAqgdmxQJwSVFr1/31r38t8tFUBfr376/XXnvN8frSNe2mT5+unTt3OvVm7dq1S//85z8LHefSXiaTyaQ5c+Zo5MiRTsObX3zxhdNM3EvreKlBgwY5hT273a5FixZp0aJFTp9Rmfe3RUdHy8fHx6l37cUXX3RafqR58+aFhmsvV95rdikfHx/dcccdRQa/vn37OmYuA6he6LED4JLL166TVGjR4ctFRkaqUaNGTtsKhmNbtmyp1157TWFhYS7XJSQkRK+++qquuuoql/ft1auXbrvttmLfj4iIKNTTWFEBAQF69NFHi12SpXHjxnrhhRdKPU5FrtmlRowYodq1axfazjAsUH3RYwfAJZcPadatW9dpQd2iWCwWXX/99U49fZeuademTRutWbNGn376qd5//33t3LlTaWlpysnJKfRA+8uFhoZq06ZN+uCDD7R161bt2rVLZ86cUW5urvz9/dW6dWt1795dffv2LbRvXFycwsLCtHbtWh0+fFhms1lBQUG67bbbdMcdd5QpZLlq5MiRateunZYvX64dO3YoMzNTLVq00PXXX68HHnhALVu2LNNxKnLNCjRv3lz9+/fXe++959jWqlUr9erVq8LnCcAzTPbKnkcPAKg2lixZooULFzpejx8/Xg899JAHawSgIhiKBYAa6tChQ3r99dcdr2vVqqXhw4d7sEYAKoqhWACoQXbu3KnJkycrKytLaWlpTpNDhg4dWuahYADeiWAHADVIVlaWfv7550Lbr7nmGv3rX//yQI0AVCaCHQDUUL6+vmrdurVuuOEGjR49utCizQCqHyZPAAAAGASTJwAAAAyCYAcAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABlEt17HLy8vT+fPn5evrK7OZbAoAAIzLZrMpOztbjRo1Uq1aJUe3ahnszp8/ryNHjni6GgAAAG5z1VVXyd/fv8Qy1TLY+fr6SpLatGmj+vXre7g2uJzVatX+/fvVvn17WSwWT1cHl6BtvBvt491oH+9m5PbJzMzUkSNHHPmnJNUy2BUMv9apU0f16tXzcG1wOavVKkmqV6+e4X65qjvaxrvRPt6N9vFuNaF9ynL7GTeoAQAAGATBDgAAwCAIdgAAAAZBsAMAADAIgh0AAIBBEOwAAAAMgmAHAABgEAQ7AAAAgyDYAQAAGATBDgAAwCAIdgAAAAbhcrD79ttvNW7cOEVFRSk4OFgfffRRqft8/fXXGjJkiEJDQ3XDDTdo/fr1hcqsXr1affr0UVhYmIYNG6aUlBRXqwYAAFCjuRzsMjIyFBwcrCeeeKJM5Y8ePaqxY8eqe/fuevfdd3XPPfdoxowZ+vzzzx1lEhMTFRcXp/Hjx2vDhg0KCQnR6NGjlZ6e7mr1AAAAaqxaru4QHR2t6OjoMpd/88031bp1az3yyCOSpGuuuUbff/+9VqxYoeuvv16SlJCQoOHDh2vo0KGSpFmzZmnbtm1at26dxowZ42oVK43dbldmrtVjn19dWa1WZeXZlJGTJ4vF7unq4BK0jXejfbwb7ePdPNU+dWtbZDKZ3PZ5pXE52Llqx44d6tmzp9O2qKgozZkzR5KUk5Oj3bt3a+zYsY73zWazevXqpeTk5BKPbbPZZLVWTfCy2+0a/vLX2v7zuSo5fo2wofRhengIbePdaB/vRvt4Nze3z5/aNtZb93ev0nDnStap8mB3+vRpNWvWzGlbs2bNdOHCBWVlZen8+fOyWq3y9/d3KuPv769Dhw6VeOwDBw5Uen0L2O12ZVy8WGXHBwAA1d/FCxe1Y8cOr+m1q/JgV5WCgoLk5+dXZcffFMFQbHlYrTbt3r1LnTqFymJh4rU3oW28G+3j3Wgf7+ap9nHHUGxGRob2799fprJVHuyaNWum06dPO207ffq0/Pz8VKdOHZnNZlkslkITJdLT0wv19F2uYN+q1KBWtc6+HmG1WlWnllkN6vpUefvANbSNd6N9vBvt492M3D6unE+VR9qIiAh99dVXTtu+/PJLRURESJJ8fHzUqVMnJSUlOd632WxKSkpSZGRkVVcPAADAMFwOdhcvXtTevXu1d+9eSdIvv/yivXv36tixY5Kk+fPna8qUKY7yI0aM0NGjR/Xss8/q4MGDWr16td5//33de++9jjKjRo3SmjVrtGHDBh08eFAzZ85UZmamYmJiKnh6AAAANYfL44y7du3S3Xff7XgdFxcnSRoyZIjmzp2rtLQ0HT9+3PF+YGCgXnrpJcXFxenVV19Vy5Yt9dRTTzmWOpGkAQMG6MyZM1q4cKHS0tLUoUMHLVu2rNShWAAAAPzB5WDXvXt37du3r9j3586dW+Q+77zzTonHjY2NVWxsrKvVAQAAwO+Y1gMAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABkGwAwAAMAiCHQAAgEEQ7AAAAAyCYAcAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABkGwAwAAMAiCHQAAgEEQ7AAAAAyCYAcAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABkGwAwAAMAiCHQAAgEEQ7AAAAAyCYAcAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABkGwAwAAMAiCHQAAgEEQ7AAAAAyCYAcAAGAQBDsAAACDINgBAAAYBMEOAADAIAh2AAAABkGwAwAAMAiCHQAAgEEQ7AAAAAyiXMFu9erV6tOnj8LCwjRs2DClpKQUWzY3N1eLFy9Wv379FBYWpsGDB+uzzz5zKmO1WhUfH68+ffooPDxc/fr105IlS2S328tTPQAAgBrJ5WCXmJiouLg4jR8/Xhs2bFBISIhGjx6t9PT0IsvHx8frrbfe0mOPPabExESNGDFCEyZM0J49exxlli5dqjfeeEOPP/64EhMTNXnyZC1btkyrVq0q/5kBAADUMC4Hu4SEBA0fPlxDhw5VUFCQZs2apTp16mjdunVFln/33Xc1btw4RUdHKzAwUCNHjlR0dLSWL1/uKJOcnKy+ffvqr3/9q1q3bq2bb75ZUVFRJfYEAgAAwFktVwrn5ORo9+7dGjt2rGOb2WxWr169lJycXOQ+ubm58vHxcdrm6+ur7du3O15HRkZqzZo1Onz4sNq1a6cffvhB33//vR555JES62Oz2WS1Wl05BbhBQZvQNt6HtvFutI93o328m5Hbx5VzcinYnT17VlarVf7+/k7b/f39dejQoSL3iYqK0ooVK9S1a1e1adNGSUlJ2rp1q1Mlx4wZowsXLqh///6yWCyyWq2aOHGiBg8eXGJ9Dhw44Er14WapqamergKKQdt4N9rHu9E+3q2mt49Lwa48pk+frhkzZqh///4ymUwKDAxUTEyM09Dt+++/r40bN2r+/PkKCgrS3r17FRcXpxYtWmjIkCHFHjsoKEh+fn5VfQpwkdVqVWpqqsLCwmSxWDxdHVyCtvFutI93o328m5HbJyMjQ/v37y9TWZeCXZMmTWSxWApNlEhPT1ezZs2K3Kdp06Z6/vnnlZ2drXPnzqlFixaaN2+eAgMDHWWeffZZjRkzRgMHDpQkBQcH69ixY3rppZdKDHZms9lwjWckFouF9vFStI13o328G+3j3YzYPq6cj0uTJ3x8fNSpUyclJSU5ttlsNiUlJSkyMrLEfX19fRUQEKC8vDx9+OGH6tu3r+O9rKwsmUwmp/IWi4XlTgAAAFzg8lDsqFGjNHXqVIWGhio8PFwrV65UZmamYmJiJElTpkxRQECAJk2aJEnauXOnTp48qQ4dOujkyZNatGiRbDab7rvvPscxe/furRdffFGtWrVyDMUmJCRo6NChlXSaAAAAxudysBswYIDOnDmjhQsXKi0tTR06dNCyZcscQ7HHjx+X2fxHR2B2drbi4+N19OhR1atXT9HR0Xr22WfVsGFDR5kZM2ZowYIFmjVrltLT09WiRQvdcccdGj9+fCWcIgAAQM1QrskTsbGxio2NLfK9yxcV7tatmxITE0s8np+fn6ZPn67p06eXpzoAAAAQz4oFAAAwDIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGUa5gt3r1avXp00dhYWEaNmyYUlJSii2bm5urxYsXq1+/fgoLC9PgwYP12WefFSp38uRJTZ48Wd27d1d4eLgGDRqk1NTU8lQPAACgRnI52CUmJiouLk7jx4/Xhg0bFBISotGjRys9Pb3I8vHx8Xrrrbf02GOPKTExUSNGjNCECRO0Z88eR5nz58/rb3/7m2rXrq2lS5dq8+bNmjp1qho1alT+MwMAAKhharm6Q0JCgoYPH66hQ4dKkmbNmqVt27Zp3bp1GjNmTKHy7777rh544AFFR0dLkkaOHKmkpCQtX75c8+bNkyQtXbpULVu2VFxcnGO/wMDAUutis9lktVpdPQVUsYI2oW28D23j3Wgf70b7eDcjt48r5+RSsMvJydHu3bs1duxYxzaz2axevXopOTm5yH1yc3Pl4+PjtM3X11fbt293vP74448VFRWlhx56SN9++60CAgI0cuRIDR8+vMT6HDhwwJXqw80YSvdetI13o328G+3j3Wp6+7gU7M6ePSur1Sp/f3+n7f7+/jp06FCR+0RFRWnFihXq2rWr2rRpo6SkJG3dutUpfR49elRvvPGGRo0apXHjxik1NVVPPfWUateurSFDhhRbn6CgIPn5+blyCnADq9Wq1NRUhYWFyWKxeLo6uARt491oH+9G+3g3I7dPRkaG9u/fX6ayLg/Fumr69OmaMWOG+vfvL5PJpMDAQMXExGjdunWOMna7XaGhoXr44YclSR07dtSPP/6oN998s8RgZzabDdd4RmKxWGgfL0XbeDfax7vRPt7NiO3jyvm4NHmiSZMmslgshSZKpKenq1mzZkXu07RpUz3//PPasWOHPvnkE23ZskX16tVzuoeuefPmuuaaa5z2u/rqq3Xs2DFXqgcAAFCjuRTsfHx81KlTJyUlJTm22Ww2JSUlKTIyssR9fX19FRAQoLy8PH344Yfq27ev470uXbro8OHDTuWPHDmiK6+80pXqAQAA1GguL3cyatQorVmzRhs2bNDBgwc1c+ZMZWZmKiYmRpI0ZcoUzZ8/31F+586d+vDDD3X06FF99913uu+++2Sz2XTfffc5ytxzzz3auXOnXnzxRf3000/auHGj1qxZo5EjR1bCKQIAANQMLt9jN2DAAJ05c0YLFy5UWlqaOnTooGXLljmGYo8fPy6z+Y+8mJ2drfj4eB09elT16tVTdHS0nn32WTVs2NBRJjw8XIsXL9a///1vLVmyRK1bt9a0adM0ePDgSjhFAACAmqFckydiY2MVGxtb5HurVq1yet2tWzclJiaWeszevXurd+/e5akOAAAAxLNiAQAADINgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBC1PF0BAABQw+VlS8d3SnZb+Y9hs6r+mQPS0SzJbKm8upUmIFTy9XPf55WCYAcAADxr7f9JP2yq0CEskkIk6YvKqJALWnWRxnzi5g8tHsEOAAB4VtoP+V8bXinVqlOuQ9glZWdny9fXV6bKq1np2t/szk8rFcEOAAB4Vk5G/tcRq6VWkeU6hM1q1e4dOxQRESGLxY1DsV6GyRMAAMCzci/mf61d37P1MACCHQAA8KyCHjufep6thwGUK9itXr1affr0UVhYmIYNG6aUlJRiy+bm5mrx4sXq16+fwsLCNHjwYH322WfFln/55ZcVHBysp59+ujxVAwAA1Yk1V7Ll5n9fm2BXUS4Hu8TERMXFxWn8+PHasGGDQkJCNHr0aKWnpxdZPj4+Xm+99ZYee+wxJSYmasSIEZowYYL27NlTqGxKSorefPNNBQcHu34mAACg+sm5+Mf3PgzFVpTLkycSEhI0fPhwDR06VJI0a9Ysbdu2TevWrdOYMWMKlX/33Xf1wAMPKDo6WpI0cuRIJSUlafny5Zo3b56j3MWLF/Wvf/1LTz31lF544YUy1cVms8lqtbp6CqhiBW1C23gf2sa70T7ejfapIlm/ySLJbrLIJotUzutr5PZx5ZxcCnY5OTnavXu3xo4d69hmNpvVq1cvJScnF7lPbm6ufHx8nLb5+vpq+/btTttmz56t6Oho9erVq8zB7sCBA65UH26Wmprq6SqgGLSNd6N9vBvtU7l8LxxVqCSbpY527NxZ4ePV9PZxKdidPXtWVqtV/v7+Ttv9/f116NChIveJiorSihUr1LVrV7Vp00ZJSUnaunWrU/rcvHmz9uzZo7Vr17pU+aCgIPn5ec9qz8hntVqVmpqqsLCwGj3l3BvRNt6N9vFutE8VOW6WPpHMdRooIiKi3IcxcvtkZGRo//79ZSpb5evYTZ8+XTNmzFD//v1lMpkUGBiomJgYrVu3TpJ0/PhxPf3001q+fLl8fX1dOrbZbDZc4xmJxWKhfbwUbePdaB/vRvtUMmuWJMnkU69SrqsR28eV83Ep2DVp0kQWi6XQRIn09HQ1a9asyH2aNm2q559/XtnZ2Tp37pxatGihefPmKTAwUJK0e/dupaenKyYmxrGP1WrVt99+q9WrVys1NdVwDQQAAH7HGnaVyqVg5+Pjo06dOikpKUn9+vWTlD+BISkpSbGxsSXu6+vrq4CAAOXm5urDDz9U//79JUk9evTQxo0bnco++uijuvrqq3X//fcT6gAAMDLWsKtULg/Fjho1SlOnTlVoaKjCw8O1cuVKZWZmOnrcpkyZooCAAE2aNEmStHPnTp08eVIdOnTQyZMntWjRItlsNt13332SJD8/P7Vv397pM+rVq6fGjRsX2g4AAAwm9/dgxxp2lcLlYDdgwACdOXNGCxcuVFpamjp06KBly5Y5hmKPHz8us/mP5fGys7MVHx+vo0ePql69eoqOjtazzz6rhg0bVt5ZAACA6qlgHTvWsKsU5Zo8ERsbW+zQ66pVq5xed+vWTYmJiS4d//JjAAAAg6LHrlLxrFgAAOA53GNXqQh2AADAc5gVW6kIdgAAwHPosatUBDsAAOA53GNXqQh2AADAc5gVW6kIdgAAwHPosatUBDsAAOA53GNXqcq1jh0AlFv2BSkvS6pf9POlYUB2u3QxTbLbXN/XZJH8mpdcxmaTLp4qX91cYbWqVla69NsJicddVp7s8/lfmRVbKQh2ANznl++lhP6SNVuKnir1nubpGsEdNk2Uvk8o//5d75MGzi/+/dVDpYMfl//4ZWSR1FmStlb5R9VM9NhVCoIdAPf55dv8UCdJR77wbF3gPkf+3+/fmCSTqez72e2S7KX/rJT3+C6yF/zHJFXdp9RQTdpJV3T2dC0MgWAHwH0KFiK9/HsYW8HN8fd/LF3Zpez7Hf1WeqVfyT8r1jzJmpP//ZRDUr2m5a9nKWxWq3bs2KGIiAhZGIqFl2LyBAD3KbhJ+vLvYWzlXc6iYGiupJ+VS0MfsyoBgh0AN8rNvOR7gl2NUd7lLArKX/pzc7mC0GcyS7V8Xa8bYDAEOwDuc2nvSg5DsTXCpUOlLvfY/V4+N+P3++2K4AiN9av0/jqguiDYAXCfS4fU6LGrGSoyVOooby++184xzMswLCAR7AC406VhLi9Lslk9Vxe4R0WGSi8NgsX9Q4CnFgBOCHYA3Ofy4Vd67YyvIkOlZrNUq27+98UN3fOcUcAJwQ6A+1we5JgZa3wVHSot2I8eO6BMCHYA3OfyIMdadsZX0eBV8Jip4v4RwHNGAScEOwDuc3mQo8fO+Co6VOrosSvmHwEF23nOKCCJYAfAnQr12BHsDK/CPXalLFJMjx3ghGAHwH0K/pK3/D47krXsjK+iwcuxll1xPXbcYwdcimAHwD3s9j+CXP3m+V/psTO+ig6Vltpjx6xY4FIEOwDuYc2R7L+vW1e/Wf5X7rEzvgr32DErFnAFwQ6Ae1w67FoQ7JgVa3yVNiu2uHXsuMcOuBTBDoB7FPwFb64t1WmU/z09dsZXabNii+uxY1YscCmCHQD3uLRnpXYpS1jAOJgVC7gVwQ6Ae1zas+JTyqKzMA5mxQJuRbAD4B5F9tgR7AyPWbGAWxHsALjHpT0rBb03rGNnfMyKBdyKYAfAPS7tWSnovaHHzvjcNiuWHjtAItgBcJcie+wIdobntlmx9NgBklTL0xUAYHBHvpDevlfKPJv/2qfeH70w+7dIT7X0WNW8jVlSpM0m0/sG+jd3Xmb+14rOij36TdE/KwXHZ1YsIIlgB6Cq/fiBdPHUH69bd5Ou6Jz/vFhr9h9/MUOm3//I5uGKVDafBlKLDuXbN6CT5OMn5Vwo/melUaDU4Iry1w8wEIIdgKpVMNzabax0/cNSg997Xf514I9ePEiSrDab9uzZo44dO8piNlCvXT1/ydevfPs2aClN2idlpJdcppZv+Y4PGAzBDkDVKrg3qkHLP0KdJNVpmP8Hf7BalVPvjNS4jWSxeLo23sPXr/zBEKhhDPRPQgBeiXXGAMBtCHYAqhbrjAGA2xDsAFQtnuUJAG5TrmC3evVq9enTR2FhYRo2bJhSUlKKLZubm6vFixerX79+CgsL0+DBg/XZZ585lXnppZc0dOhQRUZGqmfPnvr73/+uQ4cOladqALxNRR8pBQAoM5eDXWJiouLi4jR+/Hht2LBBISEhGj16tNLTi56xFB8fr7feekuPPfaYEhMTNWLECE2YMEF79uxxlPnmm2905513as2aNUpISFBeXp5Gjx6tjAwWLwWqPXrsAMBtXA52CQkJGj58uIYOHaqgoCDNmjVLderU0bp164os/+6772rcuHGKjo5WYGCgRo4cqejoaC1fvtxR5pVXXlFMTIyuvfZahYSEaO7cuTp27Jh2795d/jMD4B0c99jRYwcAVc2l5U5ycnK0e/dujR071rHNbDarV69eSk5OLnKf3Nxc+fj4OG3z9fXV9u3bi/2c3377TZLUqFGjEutjs9lktVrLWn24SUGb0DbexxNtY865KJMkq8VX4meiRPzueDfax7sZuX1cOSeXgt3Zs2dltVrl7+/vtN3f37/Ye+KioqK0YsUKde3aVW3atFFSUpK2bt1abCVtNpvmzJmjLl26qH379iXW58CBA65UH26Wmprq6SqgGO5sm8jsCzJJ2nPgJ+Ucy3bb51Zn/O54N9rHu9X09qnyBYqnT5+uGTNmqH///jKZTAoMDFRMTEyxQ7ezZs3Sjz/+qNdff73UYwcFBcnPj0UrvY3ValVqaqrCwsJkYZFVr+L2trFZZd6YI0nq2Pk6qX6zqv/MaozfHe9G+3g3I7dPRkaG9u/fX6ayLgW7Jk2ayGKxFJookZ6ermbNiv4fdtOmTfX8888rOztb586dU4sWLTRv3jwFBgYWKjt79mxt27ZNr732mlq2LP3B4Gaz2XCNZyQWi4X28VJua5u8PyZAWeo04GkKZcTvjnejfbybEdvHlfNxafKEj4+POnXqpKSkJMc2m82mpKQkRUZGlrivr6+vAgIClJeXpw8//FB9+/Z1vGe32zV79mxt3bpVK1euLDL0AaiGCmbEyiTVruvRqgBATeDyUOyoUaM0depUhYaGKjw8XCtXrlRmZqZiYmIkSVOmTFFAQIAmTZokSdq5c6dOnjypDh066OTJk1q0aJFsNpvuu+8+xzFnzZqlTZs26fnnn1f9+vWVlpYmSWrQoIHq1KlTGecJwBMca9jVk0wmz9YFAGoAl4PdgAEDdObMGS1cuFBpaWnq0KGDli1b5hiKPX78uMzmPzoCs7OzFR8fr6NHj6pevXqKjo7Ws88+q4YN/3j49xtvvCFJuuuuu5w+Ky4uzhEYAVRDrGEHAG5VrskTsbGxio2NLfK9VatWOb3u1q2bEhMTSzzevn37ylMNAN6O58QCgFvxrFgAVSfn96FYHxYnBgB3INgBqDr02AGAWxHsAFQd7rEDALci2AGoOo5ZsQzFAoA7EOwAVB167ADArQh2AKrOpevYAQCqXJU/KxZADZCyRvpioWS3Om+/cCr/K7NiAcAtCHYAKu6rF6STqcW/7x/kvroAQA1GsANQcTkX8r/e+LTUMtT5PZ8G0pVd3F8nAKiBCHYAKq5gkkTbntKVf/JsXQCgBmPyBICKY1kTAPAKBDsAFZebmf+VZU0AwKMIdgAqxmaV8rLyv6fHDgA8imAHoGIKngcr0WMHAB5GsANQMQUTJ2SSatXxaFUAoKYj2AGomEufLmEyebYuAFDDEewAVAzPgwUAr0GwA1AxBffY8TxYAPA4gh2Aisn5fSiW58ECgMcR7ABUDD12AOA1CHYAKoZ77ADAaxDsAFQMjxMDAK9BsANQMfTYAYDXINgBqJhL17EDAHgUwQ5AxTh67BiKBQBPI9gBqBhmxQKA1yDYAagYxzp2BDsA8DSCHYCKcfTYMRQLAJ5GsANQMcyKBQCvQbADUDGsYwcAXqOWpysAwAvZ7dJHM6XTP5Ze9nhK/ld67ADA4wh2AAo7uUv6It61fRq1rpKqAADKjmAHoLCs8/lf/QKk3tNKL98oULqic9XWCQBQKoIdgMIKJkQ0aCn96V6PVgUAUHZMngBQGBMiAKBaItgBKIwlTACgWiLYASiMx4QBQLVEsANQmOMxYQzFAkB1QrADUBg9dgBQLRHsABTm6LEj2AFAdVKuYLd69Wr16dNHYWFhGjZsmFJSUootm5ubq8WLF6tfv34KCwvT4MGD9dlnn1XomACqmKPHjqFYAKhOXA52iYmJiouL0/jx47VhwwaFhIRo9OjRSk9PL7J8fHy83nrrLT322GNKTEzUiBEjNGHCBO3Zs6fcxwRQxZgVCwDVkssLFCckJGj48OEaOnSoJGnWrFnatm2b1q1bpzFjxhQq/+677+qBBx5QdHS0JGnkyJFKSkrS8uXLNW/evHIds4DNZpPVanX1FFDFCtqEtvE+ZW0bc84FmSTZatWVnXZ0G353vBvt492M3D6unJNLwS4nJ0e7d+/W2LFjHdvMZrN69eql5OTkIvfJzc2Vj4+P0zZfX19t37693McscODAAVeqDzdLTU31dBVQjNLaJij9pBpJ+un4aZ3ZscMtdcIf+N3xbrSPd6vp7eNSsDt79qysVqv8/f2dtvv7++vQoUNF7hMVFaUVK1aoa9euatOmjZKSkrR161ZH+izPMQsEBQXJz8/PlVOAG1itVqWmpiosLEwWi8XT1cElyto25h3577W5JkRtOka4qXbgd8e70T7ezcjtk5GRof3795epbJU/K3b69OmaMWOG+vfvL5PJpMDAQMXExGjdunUVPrbZbDZc4xmJxWKhfbxUqW3z++QJS50GEm3odvzueDfax7sZsX1cOR+Xgl2TJk1ksVgKTWpIT09Xs2bNitynadOmev7555Wdna1z586pRYsWmjdvngIDA8t9TABVjHXsAKBacmlWrI+Pjzp16qSkpCTHNpvNpqSkJEVGRpa4r6+vrwICApSXl6cPP/xQffv2rfAxAVQRZsUCQLXk8lDsqFGjNHXqVIWGhio8PFwrV65UZmamYmJiJElTpkxRQECAJk2aJEnauXOnTp48qQ4dOujkyZNatGiRbDab7rvvvjIfE4Cb5f6+QDHr2AFAteJysBswYIDOnDmjhQsXKi0tTR06dNCyZcscw6bHjx+X2fxHR2B2drbi4+N19OhR1atXT9HR0Xr22WfVsGHDMh8TgJs5euwIdgBQnZRr8kRsbKxiY2OLfG/VqlVOr7t166bExMQKHROAG1lzJVtu/vcMxQJAtcKzYgE4K3hOrMRQLABUMwQ7AM4Kgp25llTLp+SyAACvQrAD4Myx1Am9dQBQ3VT5AsWA4SW/Jp3a6+lalInJblPrU2kypTWXTMX8u+7i6fyv3F8HANUOwQ6oiLNHpHfHe7oWZWaWFCBJJT+tL199ZqUDQHVDsAMqoqB3y7eRdN0oz9alDGx2u06dOqkWLQJkNpmKL2gySR1vdV/FAACVgmAHVETBRIOGV0g3zPJsXcrAbrXqfzt2qHlEBM+ABQADYvIEUBE8UxUA4EUIdkBF5PKEBgCA9yDYARWRQ48dAMB7EOyAinD02BHsAACeR7ADKqJg8gSL+QIAvADBDqgIeuwAAF6EYAdUhOMeu7qerQcAACLYARWTy1AsAMB7EOyAishhKBYA4D0IdkBFsEAxAMCLEOyAiiiYFcsCxQAAL0CwAyqCHjsAgBch2AEVwT12AAAvQrADKoJZsQAAL0KwAyqCHjsAgBch2AEV4bjHjh47AIDnEeyA8rLbL5kVS48dAMDzCHZAeVlzJLs1/3tmxQIAvADBDiivgt46iXXsAABegWAHlFfB/XXm2pKltmfrAgCApFqeroBXO/Sp1DhQanq1p2tS2K/Hpf3vSzarp2tSiMluV/NffpEp73vJZPJ0darOxdP5X7m/DgDgJQh2xTn7k/TqYKlluDTuc0/XprDND0v7Ej1diyKZJbWRpFQPV8Rd6jT2dA0AAJBEsCtewf1Tv/7Ps/Uozvlf8r+26SX5NfdsXS5jt9t17tw5NW7cWCYj99hJkkxS+HBPVwIAAEkEu+IVDK8VLEDrbQru7+ozQ7rqz56ty2VsVqsO7dihiIgIWSwWT1cHAIAag8kTxSlYcDYvU7LZPFuXovDEAwAAcBmCXXEuDUy5XthrxzNKAQDAZQh2xalV94/vvTHY0WMHAAAuQ7Arjtn8x9MELl2I1htYcyVbbv73PPEAAAD8jmBXkoLQ5G09djzxAAAAFIFgVxJvnRlbEDRNFsni49m6AAAAr0GwK0nBxIRcLxuKddxfV9/YT3YAAAAuIdiVxGt77ApmxHJ/HQAA+APBriRee48dM2IBAEBh5Qp2q1evVp8+fRQWFqZhw4YpJSWlxPIrVqzQTTfdpPDwcEVHR2vOnDnKzs52vG+1WhUfH68+ffooPDxc/fr105IlS2S328tTvcpTMDHB22bFsoYdAAAogsuPFEtMTFRcXJxmzZqlzp07a+XKlRo9erS2bNkif3//QuU3btyo+fPna86cOYqMjNSRI0f0yCOPyGQy6dFHH5UkLV26VG+88YaeeeYZBQUFadeuXXr00UfVoEED3X333RU/y/Kixw4AAFQjLge7hIQEDR8+XEOHDpUkzZo1S9u2bdO6des0ZsyYQuWTk5PVpUsXDRo0SJLUunVr3XLLLdq5c6dTmb59++qvf/2ro8zmzZtL7Qm02WyyWq2unkKZmWrXlVmSLfuC7FX4Oa4yZV+QWZK9dl3ZvKheBQrapCrbBuVD23g32se70T7ezcjt48o5uRTscnJytHv3bo0dO9axzWw2q1evXkpOTi5yn8jISL333ntKSUlReHi4jh49qk8//VS33nqrU5k1a9bo8OHDateunX744Qd9//33euSRR0qsz4EDB1ypvssCz2eohaSTRw/r2I4dVfpZrmh2ZJ/aSjqXkatDXlSvy6Wmpnq6CigGbePdaB/vRvt4t5rePi4Fu7Nnz8pqtRYacvX399ehQ4eK3GfQoEE6e/asRo4cKbvdrry8PI0YMULjxo1zlBkzZowuXLig/v37y2KxyGq1auLEiRo8eHCJ9QkKCpKfn58rp+ASU3pb6bAU0NRPLSIiquxzXGXK/H9SqtSoWStFeFG9ClitVqWmpiosLEwWi8XT1cElaBvvRvt4N9rHuxm5fTIyMrR///4ylXV5KNZVX3/9tV566SU98cQTCg8P188//6ynn35aS5Ys0fjx4yVJ77//vuNevKCgIO3du1dxcXFq0aKFhgwZUuyxzWZz1Taeb35oNOdlSt70Q5KXJUky+9b3rnpdxmKxGO6XyyhoG+9G+3g32se7GbF9XDkfl4JdkyZNZLFYlJ6e7rQ9PT1dzZo1K3KfBQsWaPDgwRo2bJgkKTg4WBkZGXr88cf1wAMPyGw269lnn9WYMWM0cOBAR5ljx47ppZdeKjHYVTmvX8eOWbEAAOAPLi134uPjo06dOikpKcmxzWazKSkpSZGRkUXuk5WVJbPZ+WMKkmfBciZZWVkyXfYEBYvF4j3LnXjtrFiCHQAA+IPLQ7GjRo3S1KlTFRoaqvDwcK1cuVKZmZmKiYmRJE2ZMkUBAQGaNGmSJKl3795KSEhQx44dHUOxCxYsUO/evR0Br3fv3nrxxRfVqlUrx1BsQkKCY+atx9T21nXsWO4EAAAU5nKwGzBggM6cOaOFCxcqLS1NHTp00LJlyxxDscePH3fqoXvggQdkMpkUHx+vkydPqmnTpurdu7cmTpzoKDNjxgwtWLBAs2bNUnp6ulq0aKE77rjDcQ+exziGYr0s2OUwFAsAAAor1+SJ2NhYxcbGFvneqlWrnD+gVi1NmDBBEyZMKPZ4fn5+mj59uqZPn16e6lQdr12g+PdgR48dAAC4RJXPiq3W3PVIsbT90vmfy17+t+P5X2sT7AAAwB8IdiVxR4/d6QPSkq7l29en6tbwAwAA1Q/BriTuWO7kzMH8r7XrSf5BZd+vUWvpqj9XTZ0AAEC1RLArSe1Lljux26XLlmSpFAXDvK0ipVGJlX98AABQY7i0jl2N45icYJdyM6vmMwqGeblfDgAAVBDBriSXhq2qus8uhzXpAABA5SDYlcRskWrVyf++qmbG8ngwAABQSQh2panqmbH02AEAgEpCsCuNYy27Kgp23GMHAAAqCcGuNI4euyoainU8RYKhWAAAUDEEu9JU9Vp29NgBAIBKQrArjWMtu6rusSPYAQCAiiHYlcZtPXYMxQIAgIoh2JWGWbEAAKCaINiVxjErlnXsAACAdyPYlYYeOwAAUE0Q7ErDrFgAAFBNEOxKU+WzYgt67BiKBQAAFUOwK02V99gV3GNHjx0AAKgYgl1pqvIeu7wcyZaX/z332AEAgAoi2JWmKmfFXjq8y6xYAABQQQS70lRlj13B8K65llTLp/KPDwAAahSCXWmq8h47njoBAIZw11136emnny72/T59+mjFihXuqxBqrFqeroDXq8pZsTwnFgBqhLVr16pu3bqergZqAIJdaQpCV/ZvUvpBqVFrqZZv2fY9/z8pL6v499MP5H9lRiwAGFrTpk2r/DNycnLk42O823pyc3NVu3ZtT1ej2mAotjQFPXYX06RFXaQXoySbrfT9vlwk/adj/j7F/Vk3Or8sPXYAUCy73a6MnDy3/rHb7S7X02q1avbs2frTn/6k7t27Kz4+3nGcy4dig4OD9fbbb2v8+PHq3LmzbrzxRv33v/91Ota0adPUp08fhYeH66abbtLKlSudPu+RRx7R3//+d73wwguKiorSzTffrMWLF+uWW24pVLdbb71V8fHxpZ5DSkqKRo0ape7du+tPf/qTYmNjtXv3bqcyv/76qx5//HH16tVLYWFhuuWWW/TJJ5843v/+++911113qXPnzuratatGjx6t8+fPF3kdCuq2aNEip2vz+uuva9y4cYqIiNCLL75YpushSdu2bdOgQYMUGhqqqKgozZ49W5L06KOPauzYsU5lc3Nz1bNnT7399tulXpfqhB670jRtJ111vXRsh5Tzm3R6f/7XOo1K3u+X7/K/WnxL7uEzmaXwEZVWXQAwErvdrttfTNL3P5116+de17aJ3h7XUyaTqcz7bNiwQbfffrvefvtt7dq1S48//rhatWql4cOHF1l+8eLF+te//qUpU6Zo1apVmjx5sj755BM1btxYNptNLVu21IIFC9S4cWMlJyfr8ccfV/PmzTVgwADHMZKSkuTn56eEhARJUoMGDbRkyRKlpKQoPDxckrRnzx7t27dPixcvLvUcLl68qNtuu00zZsyQJC1fvlxjxozRBx98ID8/P9lsNt1///26ePGinnvuObVp00YHDhyQ2ZzfT7R3717de++9Gjp0qKZPny6LxaKvv/5aVqu1zNex4NpMmjTJcYyyXI8333xTCQkJmjx5sqKjo/Xbb79p+/btkqRhw4YpNjZWp06dUosWLSTlh8CsrCyn62kEBLvSmC3SvZsku12a3VSy2/InUpQW7AomRgycL3W5q+rrCQAGVfZo5VlXXHGFpk2bJpPJpKuvvlr79+/XihUrig12Q4YMcfSuPfzww1q1apVSUlL0l7/8RbVr19ZDDz3kKBsYGKgdO3Zoy5YtTkGkXr16euqpp5yGYKOiorR+/XpHsFu/fr26du2qwMDAUs+hZ8+eTq+ffPJJXXfddfr222/Vu3dvffnll0pJSVFiYqLatWvnqFuBZcuWKTQ0VDNnznRsu/baa0v93MvdcsstGjp0qNO20q7Hiy++qIEDB+quu+6SxWKRJMc16NKli9q1a6d3331X999/vyRp3bp1uvnmm1W/vrEmMBLsyspkyh+WzfmtbEufOB4VxjArAJSXyWTS2+N6KjPXtR6fiqpb2+JSb50kde7c2WmfiIgIJSQkFNtbFRwc7Pi+Xr168vPz05kzZxzbVq9erXXr1unYsWPKzs5Wbm6uQkJCnI7Rvn37QvfVDR8+XNOmTdOjjz4qk8mkjRs36tFHHy3TOZw+fVrx8fH65ptvlJ6eLpvNpszMTB07dkxSfo9cy5YtHaHucnv37tXNN99cps8qSWhoaKFtJV2P9PR0nTp1Sp06dSr2mMOGDdNbb72l+++/X6dPn9bnn39e5HBudUewc4VPvfxgV5bFih2PCjPWvwQAwN1MJpPq+Rjvr6vLJwSYTCbZfr+He/PmzXrmmWc0depURUZGqn79+nrllVe0c+dOp32Kmmnbu3dv+fj4aOvWrapdu7by8vLKHLamTp2qc+fOafr06WrVqpV8fHx0xx13KDc3V5JUp06dEvcv7f2iwnJeXl6hbfXqOXeKlHY9fH1Ln9R46623at68eUpOTlZycrJat26t6667rtT9qhvj/aZUJVcWK6bHDgBqlJSUFKfXO3fuVNu2bR3Dgq7Yvn27IiMjdeeddzq2/fzzz2Xat1atWrrtttu0fv161a5dWwMHDiw1cF36uU888YSio6MlScePH9fZs3/c3xgcHKwTJ07o8OHDRfbaBQcHKykpyWnY9FJNmzbVqVOnHK8vXLigX375pUz1Kul6+Pn56corryw00eNSTZo0Ub9+/bR+/Xrt2LFDMTExpX5udcSsWFe48ngxFh8GgBrl2LFjiouL06FDh7Rp0ya99tpruvvuu8t1rLZt22rXrl36/PPPdfjwYcXHxys1NbXM+w8bNkxfffWVPv/880L3qpXkqquu0nvvvaeDBw9q586dmjx5slMo7Natm6677jo99NBD+uKLL3T06FF9+umn+uyzzyRJY8aMUWpqqmbOnKkffvhBBw8e1Ouvv+4YYu7Ro4fee+89fffdd9q3b5+mTp3qmHhR0esxfvx4bd68WatWrdKRI0e0e/durVq1qtB12bBhgw4ePKjbbrutzNelOqHHzhUu9dix+DAA1CS33XabsrKyNGzYMFksFt1999264447ynWsESNGaO/evZo4caJMJpMGDhyokSNHOgJUaa666ipFRkbq/Pnz6ty5c5k/9+mnn9Zjjz2mIUOG6IorrtDEiRP17LPPOpVZtGiRnnnmGT388MPKzMxU27ZtNWnSJElSu3bttHz5cv373//WsGHDVKdOHYWHhzsmiYwdO1a//PKLxo4dqwYNGugf//hHmXrsynI9brvtNh08eFBvvvmm5s2bp8aNGxcagu7Vq5datGihoKAgBQQElPm6VCcme3kW6/GwjIwM7d27V+3bt1eDBg3c98Gv3iod2iYNeVnqXMov61MB+YsT/yNFatLWLdXzFlarVTt27FBERES5hiBQdWgb70b7eLfq1D52u1033nijRo4cqVGjRnm6Om5Rlva5ePGi/vKXvyguLk433nijm2tYfgW5p0OHDoXuP7wcPXauKOvjxWzWP5444cNQLADAfc6cOaPNmzfr9OnThr2PzFU2m01nz57V8uXL1bBhQ/Xp08fTVaoyBDtXFAyr5pQyFHvpUC2PCwMAuFHPnj3VpEkTzZ49W40aOa+5GhkZWex+S5cuNeQsUSn//se+ffuqZcuWmjt3rmrVMm78Me6ZVYWy3mPnCH4mqTYPfQYAuM++ffuKfe+dd94p9j2j3nMmSa1bty7xuhgJwc4VZZ0V61jDrl7+wsYAAHiBtm1r1j3fNRHLnbjC1R47ZsQCAAA3KlewW716tfr06aOwsDANGzas0KKMl1uxYoVuuukmhYeHKzo6WnPmzFF2drZTmZMnT2ry5Mnq3r27wsPDNWjQIJfW7HELV++x4/46AADgRi4PxSYmJiouLk6zZs1S586dtXLlSo0ePVpbtmyRv79/ofIbN27U/PnzNWfOHEVGRurIkSN65JFHZDKZHM+uO3/+vP72t7+pe/fuWrp0qZo0aaKffvqp0E2fHlfWWbGONeyYEQsAANzH5WCXkJCg4cOHO1aynjVrlrZt26Z169ZpzJgxhconJyerS5cuGjRokKT8GxhvueUWp+fdLV26VC1btlRcXJxjW2BgoMsnU+XosQMAAF7MpWCXk5Oj3bt3a+zYsY5tZrNZvXr1UnJycpH7REZG6r333lNKSorCw8Mdjx+59dZbHWU+/vhjRUVF6aGHHtK3336rgIAAjRw5UsOHDy+xPjabTVar1ZVTqBCTpY7Mkuw5F2Ur4XNNWRfyy9WuV2I5oypoE3e2DcqGtvFutI93o328m5Hbx5VzcinYnT17VlartdCQq7+/vw4dOlTkPoMGDdLZs2c1cuRI2e125eXlacSIERo3bpyjzNGjR/XGG29o1KhRGjdunFJTU/XUU0+pdu3aGjJkSLH1OXDggCvVr7BGJ04qSFLG+TT9sGNHseWa/fSD2ko6n5mrgyWUMzqvu0cSDrSNd6N9vFtVtM9DDz2k/v37q3///qWWHTlypCZOnKiuXbsW+X5aWpr+8Y9/aM6cObrqqqsquaber6b//lT5cidff/21XnrpJT3xxBMKDw/Xzz//rKefflpLlizR+PHjJeU/+iQ0NFQPP/ywJKljx4768ccf9eabb5YY7IKCguTn51fVp/CHw79K30r1akkRERHFFjNlJ0kpUsNmV5RYzqisVqtSU1MVFhbm9Y/dqWloG+9G+3i3qmwfHx8fXXnllWX+O6Ndu3bFlrVarfr000/VpEkTQy/Eezkj//5kZGRo//79ZSrrUos3adJEFotF6enpTtvT09PVrFmzIvdZsGCBBg8erGHDhkmSgoODlZGRoccff1wPPPCAzGazmjdvrmuuucZpv6uvvloffPBBifUxm83ubbw6DSVJptzMkj83L1OSZPb1kwz2w+UKi8ViuF8uo6BtvBvt492qon1MJpNMJlOZj1tSHSwWi1q2bFmZ1StSTk6OfHx8qvxzXFWR9rHb7bJarV4XiF05H5eWO/Hx8VGnTp2UlJTk2Gaz2ZSUlFTsY0qysrJkNjt/TEEF7Xa7JKlLly46fPiwU5kjR47oyiuvdKV6Va9g8kSps2ILJk8wKxYAKsxuz19twJ1/fv/7qSzeeustRUVFyWazOW1/4IEH9Oijj+rnn3/WAw88oF69eikyMlJDhw7Vl19+WaFLcurUKd13330KDw9X3759tWXLFsd7v/zyi4KDg7V3715J+SNnwcHBSkpKUkxMjDp37qwRI0Y43UJVljr26dNHS5Ys0ZQpU9SlSxc9/vjjuvvuuzV79myncmfOnFFoaKhTVijOO++8o5iYGEVGRurPf/6zJk2aVKjz6Mcff9TYsWPVpUsXRUZGauTIkfr5558d769du1YDBw5U586d9fe//11PPfVUkddBkn799VcFBwfr66+/dro2n376qWJiYhQWFqbvv/++TNcjJydHzz33nKKjoxUaGqobbrhBb7/9tux2u2644Qa98sorTuX37t2r4OBg/fTTT6Vel4pwOZKOGjVKU6dOVWhoqMLDw7Vy5UplZmY6HjQ8ZcoUBQQEaNKkSZKk3r17KyEhQR07dnQMxS5YsEC9e/d2BLx77rlHf/vb3/Tiiy+qf//+SklJ0Zo1awr9sHhcwSzX0p484VjuhFmxAFAhdru0/Cbp6Nfu/dzAHtL/bSnT04NuvvlmPfnkk/r666/Vs2dPSdK5c+f0+eefa+nSpcrIyFB0dLQmTpwoHx8fvfPOOxo3bpy2bNmiVq1alat6CxYs0OTJkzV9+nS9++67evjhh3XttdcWGv261H/+8x898sgjatq0qZ544glNmzZNb775piSVuY7Lly/X+PHjNWHCBEnSzp079eSTT+qRRx5x9N699957atGihXr06FHqeeTl5ekf//iHrr76aqWnp2vu3Ll65JFHtHTpUkn5a9zGxsaqW7duWrlypfz8/LR9+3bl5eVJkl5//XXNnTtXkyZNUlRUlL7//ntdvFjK39FFmD9/vqZOnarAwEA1bNhQJ06cKPV6TJkyRTt27NCMGTMUEhKiX375RWfPnpXJZNLQoUO1fv16jR492vEZ69atU9euXav86R8uB7sBAwbozJkzWrhwodLS0tShQwctW7bMMRR7/Phxpx66Bx54QCaTSfHx8Tp58qSaNm2q3r17a+LEiY4y4eHhWrx4sf79739ryZIlat26taZNm6bBgwdXwilWooJ16fKyJGueZC6ma/TSR4oBACrIux/N2KhRI/3lL3/Rxo0bHcHugw8+UJMmTdS9e3eZzWaFhIQ4yv/zn//URx99pI8//lixsbHl+sybb77ZcYvTP//5T3355ZdatWqVZs6cWew+EydOVLdu3SRJY8aM0ZgxY5SdnS1fX1+FhISUqY49evTQ//3f/zleBwQE6Mknn9RHH32kAQMGSJLWr1+vmJgYmcoQim+//XbH94GBgZo+fbpuv/12Xbx4UfXr19fq1avl5+enf//736pdu7ak/PsLC7zwwgsaNWqU7rnnHlmtVp07d65c97Y/9NBD+vOf/+x43bhx4xKvx+HDh/X+++8rISFBvXr1ctS/wJAhQ7Rw4ULHiiC5ubnatGmTpk6d6nLdXFWuQeTY2NhifxhXrVrl/AG1amnChAmOdF+c3r17q3fv3uWpjvtcGtSeLLwYcyEsUAwAFWMy5feclfYox8rm4rO+Bw0apMcee0wzZ86Uj4+PNm7cqIEDB8psNuvixYtavHixtm3bprS0NFmtVmVlZenYsWPlrt7ltz9FREQ4DTkWJTg42PF98+bNJeXfI9+qVasy1zE0NNTpta+vrwYPHqx169ZpwIAB2r17t3788Ue98MILZTqPXbt2afHixfrhhx90/vx5xy1ax48fV1BQkPbu3avrrrvOEeoulZ6erlOnTjnCdEWEhYU5vS7teuzdu1cWi6XYmckBAQGKjo7W2rVrFR4erk8++UQ5OTm6+eabK1zX0vCsWFfUriu1LroRC6lVp+xlAQDFM5ny/6Hszj8uhDop//4zu92ubdu26fjx4/ruu+8cC/M/88wz2rp1qx5++GGtXr1a77zzjtq3b6/c3NyquFrFunRCQEFvWsF9gWWtY926dQsdd9iwYfryyy914sQJrV+/Xj169CjTPfIZGRkaPXq06tevr3nz5mnt2rVavHixJDk+t06dOsXu7+vrW+LxC0YP7ZfcL1kwhHu5y8+rtOtRUr0KDBs2TImJicrKytL69es1YMCAIq9fZfOuaR/ezmSS/u9DKfNs6WVr1+UeOwCoIXx9fXXjjTdq48aN+umnn9SuXTt16tRJUv4TmIYMGaIbbrhBUn5v0P/+978Kfd6OHTt02223OV7v3LlTHTp0KPfxKlLH4OBghYaGas2aNdq0aZMee+yxMu136NAhnTt3TpMnT9YVV1whKb8H7/Jjb9iwQbm5uYV67fz8/HTllVcqKSmpyPv5mjZtKil/Xb8CpfVqFijterRv3142m03ffvutYyj2ctHR0apbt67eeOMNff7553rttdfK9NkVRY+dq8xmqb5/6X8IdQBQowwaNMjxiM2C3jpJatu2rbZu3aq9e/fqhx9+0KRJkwrNoHXVli1btHbtWh0+fNhxL1d579erjDoOGzZML7/8smNGaFm0atVKtWvX1qpVq3T06FH997//1fPPP+9U5s4779SFCxf08MMPKzU1VUeOHNE777zjmNH74IMPKiEhQa+++qqOHDmiw4cPOwJUnTp1FBERoZdfflkHDx7UN998o/j4+Eq5Hq1bt9aQIUM0bdo0ffTRRzp69Ki+/vprJSYmOspYLBbFxMRo/vz5atu2bbGrh1Q2gh0AAJWgR48eatSokQ4fPuwU7B555BE1bNjQ8dSl66+/3tGbV14PPvigEhMTNXjwYL3zzjuaP3++goKCyn28itZx4MCBqlWrlgYOHFjqEGmBpk2bau7cudqyZYsGDBigpUuXFppc0KRJE61cuVIZGRm66667FBMTo7ffftvRe1cQrl5//XUNHjxYzz33nNNyInPmzJHValVMTIzmzJmjf/7zn2WqW1mux8yZM3XTTTdp5syZ6t+/vx577DFlZmY6lbn99tuVm5vrWDnEHUx2uwuL9XiJjIwM7d27V+3bt1eDBg08XR1cxmq1aseOHYqIiGCRVS9D23g32se70T7F++WXX3TDDTdo7dq1FQ6t5eWN7fPdd9/p3nvv1bZt24p9kENZFOSeDh06qF69kkcEuccOAACUS25urs6dO6f4+Hh17tzZY6HO2+Tk5OjMmTNatGiRbrrppgqFOlcR7AAA8BLvvfeennjiiSLfa9WqlTZv3uzmGpVs+/btuvvuu3XVVVdp4cKFTu999913uv/++4vdNzk5uaqr5zGbNm3S9OnT1aFDBz377LNu/WyCHQAAXqJPnz7q3Llzke952/NLJal79+7at29fke+FhobqnXfecW+FvERMTIxb76u7lPf9lAAAUEP5+fnJz8/P09WoFHXq1Knyx2ehMGbFAgAAGATBDgAAwCAIdgAAAAZBsAMAADAIgh0AAIBBEOwAAAAMgmAHAABgEAQ7AAAAg6iWCxTbbDZJUlZWltc86Bd/sFqtkvIfWkz7eBfaxrvRPt6N9vFuRm6fzMxMSX/kn5KY7Ha7vaorVNnS09N15MgRT1cDAADAba666ir5+/uXWKZaBru8vDydP39evr6+MpsZTQYAAMZls9mUnZ2tRo0alfrM4GoZ7AAAAFAY3V0AAAAGQbADAAAwCIIdAACAQRDsAAAADKLaBbvVq1erT58+CgsL07Bhw5SSkuLpKtUI3377rcaNG6eoqCgFBwfro48+cnrfbrdrwYIFioqKUnh4uO69995CS9KcO3dOkyZNUpcuXXTddddp2rRpunjxohvPwpheeuklDR06VJGRkerZs6f+/ve/69ChQ05lsrOzNWvWLHXv3l2RkZF68MEHdfr0aacyx44d05gxY9S5c2f17NlTzzzzjPLy8tx5Kob0+uuva9CgQerSpYu6dOmiO+64Q59++qnjfdrGu7z88ssKDg7W008/7dhGG3nOokWLFBwc7PTn5ptvdrxP2xRWrYJdYmKi4uLiNH78eG3YsEEhISEaPXq00tPTPV01w8vIyFBwcLCeeOKJIt9funSpVq1apZkzZ2rNmjWqW7euRo8erezsbEeZyZMn68CBA0pISNCLL76o7777To8//ri7TsGwvvnmG915551as2aNEhISlJeXp9GjRysjI8NRZs6cOfrkk08UHx+vVatW6dSpU5owYYLjfavVqrFjxyo3N1dvvvmm5s6dqw0bNmjhwoWeOCVDadmypSZPnqz169dr3bp16tGjh8aPH68ff/xREm3jTVJSUvTmm28qODjYaTtt5FnXXnut/t//+3+OP6+//rrjPdqmCPZq5Pbbb7fPmjXL8dpqtdqjoqLsL730kgdrVfO0b9/evnXrVsdrm81m//Of/2xftmyZY9uvv/5qDw0NtW/atMlut9vtBw4csLdv396ekpLiKPPpp5/ag4OD7SdOnHBf5WuA9PR0e/v27e3ffPON3W7Pb4tOnTrZ33//fUeZgvZITk622+12+7Zt2+whISH2tLQ0R5nXX3/d3qVLF3t2drZb618TdO3a1b5mzRraxotcuHDBfuONN9q/+OILe2xsrP2pp56y2+38/njawoUL7YMHDy7yPdqmaNWmxy4nJ0e7d+9Wr169HNvMZrN69eql5ORkD9YMv/zyi9LS0pzapkGDBurcubOjbZKTk9WwYUOFhYU5yvTq1Utms5nh9Er222+/SZIaNWokSdq1a5dyc3Od2ueaa65Rq1attGPHDknSjh071L59ezVr1sxRJioqShcuXNCBAwfcV3mDs1qt2rx5szIyMhQZGUnbeJHZs2crOjraqS0kfn+8wU8//aSoqCj17dtXkyZN0rFjxyTRNsWpNs+KPXv2rKxWa6FHafj7+xe6nwjulZaWJklFtk3BvQ6nT59W06ZNnd6vVauWGjVq5NgfFWez2TRnzhx16dJF7du3l5R/7WvXrq2GDRs6lfX393dc+9OnTzv9j0+S4zXtU3H79u3TiBEjlJ2drXr16mnJkiUKCgrS3r17aRsvsHnzZu3Zs0dr164t9B6/P54VHh6uuLg4tWvXTmlpaVqyZInuvPNObdy4kbYpRrUJdgBKN2vWLP34449O96DA89q1a6d33nlHv/32mz744ANNnTpVr732mqerBUnHjx/X008/reXLl8vX19fT1cFloqOjHd+HhISoc+fO6t27t95//33VqVPHgzXzXtVmKLZJkyayWCyFJkqkp6cXSuNwr+bNm0tSiW3TrFkznTlzxun9gmf+FuyPipk9e7a2bdumlStXqmXLlo7tzZo1U25urn799Ven8unp6Y5r36xZs0IzyQpe0z4V5+Pjo7Zt2yo0NFSTJk1SSEiIXn31VdrGC+zevVvp6emKiYlRx44d1bFjR33zzTdatWqVOnbsSBt5mYYNG+qqq67Szz//TNsUo9oEOx8fH3Xq1ElJSUmObTabTUlJSYqMjPRgzdC6dWs1b97cqW0uXLignTt3OtomMjJSv/76q3bt2uUo89VXX8lmsyk8PNztdTYSu92u2bNna+vWrVq5cqUCAwOd3g8NDVXt2rWd2ufQoUM6duyYIiIiJEkRERHav3+/Uzj/8ssv5efnp6CgILecR01is9mUk5ND23iBHj16aOPGjXrnnXccf0JDQzVo0CDH97SR97h48aKOHj2q5s2b0zbFqFZDsaNGjdLUqVMVGhqq8PBwrVy5UpmZmYqJifF01Qzv4sWL+vnnnx2vf/nlF+3du1eNGjVSq1atdPfdd+uFF15Q27Zt1bp1ay1YsEAtWrRQv379JOXf0Hr99dfrscce06xZs5Sbm6snn3xSAwcOVEBAgKdOyxBmzZqlTZs26fnnn1f9+vUd9400aNBAderUUYMGDTR06FDNnTtXjRo1kp+fn5566ilFRkY6/ucXFRWloKAgTZkyRf/617+Ulpam+Ph43XnnnfLx8fHg2VV/8+fP11/+8hddccUVunjxojZt2qRvvvlGr7zyCm3jBfz8/Bz3oxaoV6+eGjdu7NhOG3nOM888o969e6tVq1Y6deqUFi1aJLPZrFtuuYXfn2KY7Ha73dOVcMVrr72mV155RWlpaerQoYNmzJihzp07e7pahvf111/r7rvvLrR9yJAhmjt3rux2uxYuXKg1a9bo119/1Z/+9Cc98cQTateunaPsuXPn9OSTT+rjjz+W2WzWjTfeqBkzZqh+/fruPBXDuXzNrQJxcXGOf/RkZ2dr7ty52rx5s3JychQVFaUnnnjCaSjif//7n2bOnKlvvvlGdevW1ZAhQzRp0iTVqlWt/v3ndaZNm6avvvpKp06dUoMGDRQcHKz7779ff/7znyXRNt7orrvuUkhIiKZPny6JNvKkiRMn6ttvv9W5c+fUtGlT/elPf9LEiRPVpk0bSbRNUapdsAMAAEDRqs09dgAAACgZwQ4AAMAgCHYAAAAGQbADAAAwCIIdAACAQRDsAAAADIJgBwAAYBAEOwAAAIMg2AEAABgEwQ4AAMAgCHYAAAAG8f8BPmm/mZWUXy0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_keras_sequential_df = pd.DataFrame(history_keras_sequential.history)\n",
    "history_keras_sequential_df.loc[25:, [\"loss\", \"val_loss\"]].plot(title=\"Cross entropy\")\n",
    "history_keras_sequential_df.loc[25:, [\"binary_accuracy\", \"val_binary_accuracy\"]].plot(title=\"Accuracy\")\n",
    "display(f\"val_binary_accuracy: {max(history_keras_sequential_df[\"val_binary_accuracy\"])}\")\n",
    "display(f\"val_loss: {min(history_keras_sequential_df[\"val_loss\"])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
